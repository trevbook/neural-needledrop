{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Creating a Neural Search Method**\n",
    "Now that I've got some helpful methods within the **`01. Writing Postgres Queries`** notebook, I can spend some time writing a \"neural search\" method. This will be used for the API. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup\n",
    "The cells below will set up the rest of the notebook.\n",
    "\n",
    "I'll start by configuring the kernel: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d:\\data\\programming\\neural-needledrop\\api\n"
     ]
    }
   ],
   "source": [
    "# Change the working directory \n",
    "%cd ..\n",
    "\n",
    "# Enable the autoreload extension, which will automatically load in new code as it's written\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I'll import some necessary modules:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General import statements\n",
    "import pandas as pd\n",
    "import datetime\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "# Importing custom modules\n",
    "from utils.settings import (\n",
    "    POSTGRES_USER,\n",
    "    POSTGRES_PASSWORD,\n",
    "    POSTGRES_HOST,\n",
    "    POSTGRES_PORT,\n",
    "    POSTGRES_DB,\n",
    ")\n",
    "import utils.postgres_queries as pg_queries\n",
    "import utils.postgres as postgres\n",
    "from sqlalchemy import create_engine, MetaData\n",
    "from sqlalchemy.orm import sessionmaker, declarative_base"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'll also set up my connection to the Postgres server: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the connection string to the database\n",
    "postgres_connection_string = f\"postgresql://{POSTGRES_USER}:{POSTGRES_PASSWORD}@{POSTGRES_HOST}:{POSTGRES_PORT}/{POSTGRES_DB}\"\n",
    "\n",
    "# Create the connection engine\n",
    "engine = create_engine(postgres_connection_string)\n",
    "metadata = MetaData()\n",
    "session = sessionmaker(bind=engine)()\n",
    "Base = declarative_base()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Prototyping Neural Search**\n",
    "Below, I'm going to prototype a search method. \n",
    "\n",
    "I'll start by parameterizing the search:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameterize the search\n",
    "query = \"Love Me Forever, which was a very nice, airy, euphoric ballad, is just a minute and change\"\n",
    "release_date_filter = [datetime.datetime(2010, 1, 1), datetime.datetime(2024, 6, 1)]\n",
    "video_type_filter = [\"album_review\", \"mixtape_review\"]\n",
    "review_score_filter = [8, 10]\n",
    "\n",
    "# Extra parameters\n",
    "n_chunks_to_consider_initially = 250\n",
    "n_most_similar_chunks_per_video = 10\n",
    "n_videos_to_return = 10\n",
    "n_segment_chunks_to_showcase = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, I'll try and identify the most similar segments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ProgrammingError",
     "evalue": "(psycopg2.errors.UndefinedColumn) column text_segments_to_fetch.video_url does not exist\nLINE 10:             text_segments_to_fetch.video_url = transcription...\n                     ^\n\n[SQL: \n            SELECT\n            transcriptions.*,\n            text_segments_to_fetch.embedding_id\n            FROM\n            transcriptions\n            JOIN\n            text_segments_to_fetch\n            ON\n            text_segments_to_fetch.video_url = transcriptions.url\n            ]\n(Background on this error at: https://sqlalche.me/e/20/f405)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUndefinedColumn\u001b[0m                           Traceback (most recent call last)",
      "File \u001b[1;32md:\\data\\programming\\neural-needledrop\\.venv\\Lib\\site-packages\\sqlalchemy\\engine\\base.py:1969\u001b[0m, in \u001b[0;36mConnection._exec_single_context\u001b[1;34m(self, dialect, context, statement, parameters)\u001b[0m\n\u001b[0;32m   1968\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m evt_handled:\n\u001b[1;32m-> 1969\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdialect\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdo_execute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1970\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcursor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstr_statement\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meffective_parameters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\n\u001b[0;32m   1971\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1973\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_has_events \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine\u001b[38;5;241m.\u001b[39m_has_events:\n",
      "File \u001b[1;32md:\\data\\programming\\neural-needledrop\\.venv\\Lib\\site-packages\\sqlalchemy\\engine\\default.py:922\u001b[0m, in \u001b[0;36mDefaultDialect.do_execute\u001b[1;34m(self, cursor, statement, parameters, context)\u001b[0m\n\u001b[0;32m    921\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdo_execute\u001b[39m(\u001b[38;5;28mself\u001b[39m, cursor, statement, parameters, context\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m--> 922\u001b[0m     \u001b[43mcursor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstatement\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mUndefinedColumn\u001b[0m: column text_segments_to_fetch.video_url does not exist\nLINE 10:             text_segments_to_fetch.video_url = transcription...\n                     ^\n",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mProgrammingError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Run the query\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m similar_chunks_df \u001b[38;5;241m=\u001b[39m \u001b[43mpg_queries\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmost_similar_embeddings_to_text_filtered\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_chunks_to_consider_initially\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrelease_date_filter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrelease_date_filter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvideo_type_filter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvideo_type_filter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreview_score_filter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreview_score_filter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43minclude_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\data\\programming\\neural-needledrop\\api\\utils\\postgres_queries.py:399\u001b[0m, in \u001b[0;36mmost_similar_embeddings_to_text_filtered\u001b[1;34m(text, engine, n, release_date_filter, video_type_filter, review_score_filter, model, include_text, logger)\u001b[0m\n\u001b[0;32m    394\u001b[0m query_embedding \u001b[38;5;241m=\u001b[39m embed_text(\n\u001b[0;32m    395\u001b[0m     text, model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[0;32m    396\u001b[0m )\n\u001b[0;32m    398\u001b[0m \u001b[38;5;66;03m# Call the most_similar_embeddings method\u001b[39;00m\n\u001b[1;32m--> 399\u001b[0m most_similar_embeddings_df \u001b[38;5;241m=\u001b[39m \u001b[43mmost_similar_embeddings_filtered\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    400\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquery_embedding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    401\u001b[0m \u001b[43m    \u001b[49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    402\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    403\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrelease_date_filter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrelease_date_filter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    404\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvideo_type_filter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvideo_type_filter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    405\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreview_score_filter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreview_score_filter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    406\u001b[0m \u001b[43m    \u001b[49m\u001b[43minclude_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minclude_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    407\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlogger\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogger\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    408\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    410\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m most_similar_embeddings_df\n",
      "File \u001b[1;32md:\\data\\programming\\neural-needledrop\\api\\utils\\postgres_queries.py:314\u001b[0m, in \u001b[0;36mmost_similar_embeddings_filtered\u001b[1;34m(embedding, engine, n, release_date_filter, video_type_filter, review_score_filter, include_text, logger)\u001b[0m\n\u001b[0;32m    311\u001b[0m     conn\u001b[38;5;241m.\u001b[39mcommit()\n\u001b[0;32m    313\u001b[0m \u001b[38;5;66;03m# Now, we're going to query all of the text\u001b[39;00m\n\u001b[1;32m--> 314\u001b[0m fetched_text_segments_df \u001b[38;5;241m=\u001b[39m \u001b[43mquery_postgres\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    315\u001b[0m \u001b[38;5;250;43m    \u001b[39;49m\u001b[38;5;124;43;03m\"\"\"\u001b[39;49;00m\n\u001b[0;32m    316\u001b[0m \u001b[38;5;124;43;03m    SELECT\u001b[39;49;00m\n\u001b[0;32m    317\u001b[0m \u001b[38;5;124;43;03m    transcriptions.*,\u001b[39;49;00m\n\u001b[0;32m    318\u001b[0m \u001b[38;5;124;43;03m    text_segments_to_fetch.embedding_id\u001b[39;49;00m\n\u001b[0;32m    319\u001b[0m \u001b[38;5;124;43;03m    FROM\u001b[39;49;00m\n\u001b[0;32m    320\u001b[0m \u001b[38;5;124;43;03m    transcriptions\u001b[39;49;00m\n\u001b[0;32m    321\u001b[0m \u001b[38;5;124;43;03m    JOIN\u001b[39;49;00m\n\u001b[0;32m    322\u001b[0m \u001b[38;5;124;43;03m    text_segments_to_fetch\u001b[39;49;00m\n\u001b[0;32m    323\u001b[0m \u001b[38;5;124;43;03m    ON\u001b[39;49;00m\n\u001b[0;32m    324\u001b[0m \u001b[38;5;124;43;03m    text_segments_to_fetch.video_url = transcriptions.url\u001b[39;49;00m\n\u001b[0;32m    325\u001b[0m \u001b[38;5;124;43;03m    \"\"\"\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    326\u001b[0m \u001b[43m    \u001b[49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    327\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    329\u001b[0m \u001b[38;5;66;03m# Combine each of the text segments\u001b[39;00m\n\u001b[0;32m    330\u001b[0m combined_text_segment_df_records \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[1;32md:\\data\\programming\\neural-needledrop\\api\\utils\\postgres.py:102\u001b[0m, in \u001b[0;36mquery_postgres\u001b[1;34m(query, engine, logger)\u001b[0m\n\u001b[0;32m    100\u001b[0m logger\u001b[38;5;241m.\u001b[39merror(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError executing query \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquery\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    101\u001b[0m conn\u001b[38;5;241m.\u001b[39mrollback()\n\u001b[1;32m--> 102\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "File \u001b[1;32md:\\data\\programming\\neural-needledrop\\api\\utils\\postgres.py:96\u001b[0m, in \u001b[0;36mquery_postgres\u001b[1;34m(query, engine, logger)\u001b[0m\n\u001b[0;32m     94\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m engine\u001b[38;5;241m.\u001b[39mconnect() \u001b[38;5;28;01mas\u001b[39;00m conn:\n\u001b[0;32m     95\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 96\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_sql_query\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     97\u001b[0m         logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSuccessfully executed query: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquery\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     98\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32md:\\data\\programming\\neural-needledrop\\.venv\\Lib\\site-packages\\pandas\\io\\sql.py:486\u001b[0m, in \u001b[0;36mread_sql_query\u001b[1;34m(sql, con, index_col, coerce_float, params, parse_dates, chunksize, dtype, dtype_backend)\u001b[0m\n\u001b[0;32m    483\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m dtype_backend \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mno_default\n\u001b[0;32m    485\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m pandasSQL_builder(con) \u001b[38;5;28;01mas\u001b[39;00m pandas_sql:\n\u001b[1;32m--> 486\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpandas_sql\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_query\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    487\u001b[0m \u001b[43m        \u001b[49m\u001b[43msql\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    488\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindex_col\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex_col\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    489\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    490\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcoerce_float\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcoerce_float\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    491\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparse_dates\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparse_dates\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    492\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    493\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    494\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype_backend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype_backend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    495\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\data\\programming\\neural-needledrop\\.venv\\Lib\\site-packages\\pandas\\io\\sql.py:1776\u001b[0m, in \u001b[0;36mSQLDatabase.read_query\u001b[1;34m(self, sql, index_col, coerce_float, parse_dates, params, chunksize, dtype, dtype_backend)\u001b[0m\n\u001b[0;32m   1719\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mread_query\u001b[39m(\n\u001b[0;32m   1720\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1721\u001b[0m     sql: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1728\u001b[0m     dtype_backend: DtypeBackend \u001b[38;5;241m|\u001b[39m Literal[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumpy\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumpy\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1729\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Iterator[DataFrame]:\n\u001b[0;32m   1730\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1731\u001b[0m \u001b[38;5;124;03m    Read SQL query into a DataFrame.\u001b[39;00m\n\u001b[0;32m   1732\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1774\u001b[0m \n\u001b[0;32m   1775\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1776\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43msql\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1777\u001b[0m     columns \u001b[38;5;241m=\u001b[39m result\u001b[38;5;241m.\u001b[39mkeys()\n\u001b[0;32m   1779\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32md:\\data\\programming\\neural-needledrop\\.venv\\Lib\\site-packages\\pandas\\io\\sql.py:1599\u001b[0m, in \u001b[0;36mSQLDatabase.execute\u001b[1;34m(self, sql, params)\u001b[0m\n\u001b[0;32m   1597\u001b[0m args \u001b[38;5;241m=\u001b[39m [] \u001b[38;5;28;01mif\u001b[39;00m params \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m [params]\n\u001b[0;32m   1598\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(sql, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m-> 1599\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcon\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexec_driver_sql\u001b[49m\u001b[43m(\u001b[49m\u001b[43msql\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1600\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcon\u001b[38;5;241m.\u001b[39mexecute(sql, \u001b[38;5;241m*\u001b[39margs)\n",
      "File \u001b[1;32md:\\data\\programming\\neural-needledrop\\.venv\\Lib\\site-packages\\sqlalchemy\\engine\\base.py:1778\u001b[0m, in \u001b[0;36mConnection.exec_driver_sql\u001b[1;34m(self, statement, parameters, execution_options)\u001b[0m\n\u001b[0;32m   1773\u001b[0m execution_options \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_execution_options\u001b[38;5;241m.\u001b[39mmerge_with(\n\u001b[0;32m   1774\u001b[0m     execution_options\n\u001b[0;32m   1775\u001b[0m )\n\u001b[0;32m   1777\u001b[0m dialect \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdialect\n\u001b[1;32m-> 1778\u001b[0m ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execute_context\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1779\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdialect\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1780\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdialect\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecution_ctx_cls\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_init_statement\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1781\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstatement\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1782\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1783\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexecution_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1784\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstatement\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1785\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdistilled_parameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1786\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1788\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ret\n",
      "File \u001b[1;32md:\\data\\programming\\neural-needledrop\\.venv\\Lib\\site-packages\\sqlalchemy\\engine\\base.py:1848\u001b[0m, in \u001b[0;36mConnection._execute_context\u001b[1;34m(self, dialect, constructor, statement, parameters, execution_options, *args, **kw)\u001b[0m\n\u001b[0;32m   1843\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exec_insertmany_context(\n\u001b[0;32m   1844\u001b[0m         dialect,\n\u001b[0;32m   1845\u001b[0m         context,\n\u001b[0;32m   1846\u001b[0m     )\n\u001b[0;32m   1847\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1848\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_exec_single_context\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1849\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdialect\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstatement\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\n\u001b[0;32m   1850\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\data\\programming\\neural-needledrop\\.venv\\Lib\\site-packages\\sqlalchemy\\engine\\base.py:1988\u001b[0m, in \u001b[0;36mConnection._exec_single_context\u001b[1;34m(self, dialect, context, statement, parameters)\u001b[0m\n\u001b[0;32m   1985\u001b[0m     result \u001b[38;5;241m=\u001b[39m context\u001b[38;5;241m.\u001b[39m_setup_result_proxy()\n\u001b[0;32m   1987\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m-> 1988\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle_dbapi_exception\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1989\u001b[0m \u001b[43m        \u001b[49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstr_statement\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meffective_parameters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcursor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\n\u001b[0;32m   1990\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1992\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32md:\\data\\programming\\neural-needledrop\\.venv\\Lib\\site-packages\\sqlalchemy\\engine\\base.py:2344\u001b[0m, in \u001b[0;36mConnection._handle_dbapi_exception\u001b[1;34m(self, e, statement, parameters, cursor, context, is_sub_exec)\u001b[0m\n\u001b[0;32m   2342\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m should_wrap:\n\u001b[0;32m   2343\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m sqlalchemy_exception \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 2344\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m sqlalchemy_exception\u001b[38;5;241m.\u001b[39mwith_traceback(exc_info[\u001b[38;5;241m2\u001b[39m]) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m   2345\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   2346\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m exc_info[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32md:\\data\\programming\\neural-needledrop\\.venv\\Lib\\site-packages\\sqlalchemy\\engine\\base.py:1969\u001b[0m, in \u001b[0;36mConnection._exec_single_context\u001b[1;34m(self, dialect, context, statement, parameters)\u001b[0m\n\u001b[0;32m   1967\u001b[0m                 \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m   1968\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m evt_handled:\n\u001b[1;32m-> 1969\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdialect\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdo_execute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1970\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcursor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstr_statement\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meffective_parameters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\n\u001b[0;32m   1971\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1973\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_has_events \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine\u001b[38;5;241m.\u001b[39m_has_events:\n\u001b[0;32m   1974\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch\u001b[38;5;241m.\u001b[39mafter_cursor_execute(\n\u001b[0;32m   1975\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1976\u001b[0m         cursor,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1980\u001b[0m         context\u001b[38;5;241m.\u001b[39mexecutemany,\n\u001b[0;32m   1981\u001b[0m     )\n",
      "File \u001b[1;32md:\\data\\programming\\neural-needledrop\\.venv\\Lib\\site-packages\\sqlalchemy\\engine\\default.py:922\u001b[0m, in \u001b[0;36mDefaultDialect.do_execute\u001b[1;34m(self, cursor, statement, parameters, context)\u001b[0m\n\u001b[0;32m    921\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdo_execute\u001b[39m(\u001b[38;5;28mself\u001b[39m, cursor, statement, parameters, context\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m--> 922\u001b[0m     \u001b[43mcursor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstatement\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mProgrammingError\u001b[0m: (psycopg2.errors.UndefinedColumn) column text_segments_to_fetch.video_url does not exist\nLINE 10:             text_segments_to_fetch.video_url = transcription...\n                     ^\n\n[SQL: \n            SELECT\n            transcriptions.*,\n            text_segments_to_fetch.embedding_id\n            FROM\n            transcriptions\n            JOIN\n            text_segments_to_fetch\n            ON\n            text_segments_to_fetch.video_url = transcriptions.url\n            ]\n(Background on this error at: https://sqlalche.me/e/20/f405)"
     ]
    }
   ],
   "source": [
    "# Run the query\n",
    "similar_chunks_df = pg_queries.most_similar_embeddings_to_text_filtered(\n",
    "    text=query,\n",
    "    engine=engine,\n",
    "    n=n_chunks_to_consider_initially,\n",
    "    release_date_filter=release_date_filter,\n",
    "    video_type_filter=video_type_filter,\n",
    "    review_score_filter=review_score_filter,\n",
    "    include_text=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this in hand, I want to aggregate across a bunch of videos, and try to determine which video has the highest scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Groupby `url`, and take the top `n_most_similar_chunks_per_video` chunks per video\n",
    "aggregated_similar_chunks_df = similar_chunks_df.groupby(\"url\").head(\n",
    "    n_most_similar_chunks_per_video\n",
    ")\n",
    "\n",
    "# Aggregate the similarity statistics\n",
    "aggregated_similar_chunks_df = (\n",
    "    aggregated_similar_chunks_df.groupby(\"url\")\n",
    "    .agg(\n",
    "        median_similarity=(\"cos_sim\", \"median\"),\n",
    "        n_similar_chunks=(\"cos_sim\", \"count\"),\n",
    "    )\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# Add a weighted median similarity column\n",
    "aggregated_similar_chunks_df[\"weighted_median_similarity\"] = (\n",
    "    aggregated_similar_chunks_df[\"median_similarity\"]\n",
    "    * aggregated_similar_chunks_df[\"n_similar_chunks\"]\n",
    ")\n",
    "\n",
    "# Sort by the weighted median similarity\n",
    "aggregated_similar_chunks_df = aggregated_similar_chunks_df.sort_values(\n",
    "    \"weighted_median_similarity\", ascending=False\n",
    ").head(n_videos_to_return)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we're going to get some metadata about each video back. This will involve uploading a temporary table to Postgres, and then joining it to the `video_metadata` table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a temporary table called `temp_similar_chunks` that is the aggregated_similar_chunks_df DataFrame\n",
    "with engine.connect() as conn:\n",
    "    aggregated_similar_chunks_df.to_sql(\n",
    "        \"temp_similar_chunks\", conn, if_exists=\"replace\", index=False\n",
    "    )\n",
    "\n",
    "# Now, select the entire `video_metadata` table for each of the videos in the `temp_similar_chunks` table\n",
    "similar_chunks_video_metadata_df = postgres.query_postgres(\n",
    "    \"\"\"\n",
    "    SELECT \n",
    "        video_metadata.*, \n",
    "        temp_similar_chunks.median_similarity, \n",
    "        temp_similar_chunks.n_similar_chunks, \n",
    "        temp_similar_chunks.weighted_median_similarity\n",
    "    FROM video_metadata\n",
    "    JOIN temp_similar_chunks\n",
    "    ON video_metadata.url = temp_similar_chunks.url\n",
    "    ORDER BY temp_similar_chunks.weighted_median_similarity DESC\n",
    "    \"\"\",\n",
    "    engine=engine,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we're going to prepare our results. This will just be the `similar_chunks_video_metadata_df`, except also containing the `n_segment_chunks_to_showcase` most similar segment chunks per video. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame containing the segment chunks I want to showcase\n",
    "segment_chunks_to_showcase_df = (\n",
    "    (\n",
    "        similar_chunks_df[\n",
    "            similar_chunks_df[\"url\"].isin(\n",
    "                similar_chunks_video_metadata_df[\"url\"].unique()\n",
    "            )\n",
    "        ]\n",
    "        .sort_values(\"cos_sim\", ascending=False)\n",
    "        .groupby(\"url\")\n",
    "        .head(n_segment_chunks_to_showcase)\n",
    "        .sort_values([\"url\", \"cos_sim\"], ascending=False)\n",
    "    )\n",
    "    .groupby(\"url\")\n",
    "    .agg(\n",
    "        top_segment_chunks=(\"text\", lambda x: list(x)),\n",
    "    )\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# Merge this DataFrame with the video metadata\n",
    "segment_chunks_to_showcase_df = segment_chunks_to_showcase_df.merge(\n",
    "    similar_chunks_video_metadata_df, on=\"url\"\n",
    ").sort_values(\"weighted_median_similarity\", ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, I'm going to print the results using some nice formatting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in segment_chunks_to_showcase_df.head(3).iterrows():\n",
    "    display(Markdown(f\"**{row['title']}**\"))\n",
    "    display(Markdown(\"\\n\".join([f\"* {chunk}\" for chunk in row['top_segment_chunks']])))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Functionalized Version**\n",
    "I took all of the code above and wrote a single method from it. Below, I'll show it off:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.search import neural_search\n",
    "\n",
    "# Run the search\n",
    "neural_search(\n",
    "    query=\"fuzzy muted math rock guitar licks\",\n",
    "    release_date_filter=None,\n",
    "    video_type_filter=None,\n",
    "    review_score_filter=None,\n",
    "    n_most_similar_chunks_per_video=8,\n",
    "    n_videos_to_return=3,\n",
    "    n_segment_chunks_to_showcase=3,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
