{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Optimizing Embedding Indices**\n",
    "After doing a little research, it seems that `pgvector` requires the use of an index in order to do approximate nearest neighbor search. There are a couple of different choices I have w.r.t. building an index, so I want to ensure that the index built resembles the \"real results\" (i.e., exact-nearest-neighbor search results) as much as possible. \n",
    "\n",
    "This notebook will contain some experiments on that! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup\n",
    "The cells below will set up the rest of the notebook.\n",
    "\n",
    "I'll start by configuring the kernel: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the working directory \n",
    "%cd ..\n",
    "\n",
    "# Enable the autoreload extension, which will automatically load in new code as it's written\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I'll import some necessary modules:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General import statements\n",
    "import pandas as pd\n",
    "import time\n",
    "from pandas_gbq import read_gbq\n",
    "from sqlalchemy import create_engine, MetaData\n",
    "from sqlalchemy.orm import sessionmaker, declarative_base\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "from google.cloud import storage\n",
    "import json\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from scipy.stats import kendalltau\n",
    "import plotly.express as px\n",
    "\n",
    "# Importing modules custom-built for this project\n",
    "from utils.settings import (\n",
    "    GBQ_PROJECT_ID,\n",
    "    GBQ_DATASET_ID,\n",
    "    POSTGRES_USER,\n",
    "    POSTGRES_PASSWORD,\n",
    "    POSTGRES_HOST,\n",
    "    POSTGRES_PORT,\n",
    "    POSTGRES_DB,\n",
    "    LOG_TO_CONSOLE,\n",
    ")\n",
    "from utils.logging import get_logger\n",
    "from utils.postgres import query_postgres, upload_to_table\n",
    "from utils.postgres_queries import most_similar_embeddings_to_text_filtered\n",
    "from utils.search import neural_search\n",
    "\n",
    "# Set up a logger for this notebook\n",
    "logger = get_logger(\"postgres_notebook\", log_to_console=LOG_TO_CONSOLE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next up: we're going to set up the Postgres engine via SQLAlchemy!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the connection string to the database\n",
    "postgres_connection_string = f\"postgresql://{POSTGRES_USER}:{POSTGRES_PASSWORD}@{POSTGRES_HOST}:{POSTGRES_PORT}/{POSTGRES_DB}\"\n",
    "\n",
    "# Create the connection engine\n",
    "engine = create_engine(postgres_connection_string)\n",
    "metadata = MetaData()\n",
    "session = sessionmaker(bind=engine)()\n",
    "Base = declarative_base()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And, finally: below, I'll declare a couple of queries for testing the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define some different queries to test throughout the notebook\n",
    "queries_to_test = [\n",
    "    \"fear and uncertainty of the future\",\n",
    "    \"catchy rhythmic synths, addictive shredding electric guitar\",\n",
    "    \"a sense of longing and nostalgia for the past\",\n",
    "    \"math rock glitch synths amidst an upbeat rhythm\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exact Neighbor Search\n",
    "Before I create any indices, I want to test out the \"exact neighbor search\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the SET max_parallel_workers_per_gather = 4;\n",
    "query_postgres(\"SET max_parallel_workers_per_gather = 6;\", engine=engine)\n",
    "\n",
    "# Drop the index if it already exists\n",
    "query_postgres(\n",
    "    \"DROP INDEX IF EXISTS embeddings_embedding_idx;\",\n",
    "    engine=engine,\n",
    "    logger=logger,\n",
    ")\n",
    "\n",
    "# We're going to store the results of the queries in this list, and then concatenate them into a single DataFrame at the end\n",
    "exact_search_query_result_dfs = []\n",
    "\n",
    "# Iterate through each of the queries and run them in the database\n",
    "for query in tqdm(queries_to_test):\n",
    "\n",
    "    # Use the neural search for the current query\n",
    "    start_time = time.time()\n",
    "    cur_query_results = neural_search(\n",
    "        query=query,\n",
    "        n_videos_to_return=10,\n",
    "        nearest_neighbors_to_screen=None,\n",
    "    )\n",
    "    query_time = time.time() - start_time\n",
    "\n",
    "    # Load the results into a DataFrame\n",
    "    cur_query_results_df = pd.DataFrame.from_records(json.loads(cur_query_results))\n",
    "\n",
    "    # Add the query to the DataFrame\n",
    "    cur_query_results_df[\"query\"] = query\n",
    "\n",
    "    # Add the query time to the DataFrame\n",
    "    cur_query_results_df[\"query_time\"] = query_time\n",
    "\n",
    "    # Append the results to the list\n",
    "    exact_search_query_result_dfs.append(cur_query_results_df)\n",
    "\n",
    "# Finally, concatenate the results into a single DataFrame\n",
    "exact_search_query_results_df = pd.concat(exact_search_query_result_dfs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Approximate Nearest Neighbor Search with Indices\n",
    "Next up, I want to try to create a couple of different indices. For each index, I'm going to try to run the \"post-filtering\" approach using different amounts of `nearest_neighbors_to_screen`. The goal here: understand which (`index_type`, `index_build_parameters`, `nearest_neighbors_to_screen`) configurations get me closest to the results I got for the exact neighbor search. \n",
    "\n",
    "I'll start by generating a query that'll build an index with a particular configuration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_embeddings_index(\n",
    "    index_type: str, index_build_parameters: dict, distance_metric: str\n",
    "):\n",
    "    \"\"\"\n",
    "    This method will create an index on the embeddings table in the Postgres database.\n",
    "    \"\"\"\n",
    "\n",
    "    # First: drop the index if it already exists\n",
    "    query_postgres(\n",
    "        \"DROP INDEX IF EXISTS embeddings_embedding_idx;\",\n",
    "        engine=engine,\n",
    "        logger=logger,\n",
    "    )\n",
    "\n",
    "    # Unpack the index_build_parameters into a tuple\n",
    "    index_build_param_tuple = (\n",
    "        \"(\" + \", \".join([f\"{k} = {v}\" for k, v in index_build_parameters.items()]) + \")\"\n",
    "    )\n",
    "\n",
    "    # Build the index creation query if the index type is \"hnsw\"\n",
    "    if index_type == \"hnsw\":\n",
    "\n",
    "        # Create the index creation query\n",
    "        index_creation_str = f\"CREATE INDEX ON embeddings USING hnsw (embedding {distance_metric}) WITH {index_build_param_tuple};\"\n",
    "\n",
    "    # Build the index creation query if the index type is \"ivfflat\"\n",
    "    elif index_type == \"ivfflat\":\n",
    "\n",
    "        # Create the index creation query\n",
    "        index_creation_str = f\"CREATE INDEX ON embeddings USING ivfflat (embedding {distance_metric}) WITH {index_build_param_tuple};\"\n",
    "\n",
    "    # Now, we're going to create the embeddings index\n",
    "    print(f\"RUNNING THE FOLLOWING QUERY: \\n{index_creation_str}\\n\")\n",
    "    query_postgres(\n",
    "        index_creation_str,\n",
    "        engine=engine,\n",
    "        logger=logger,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, with this method in hand, I'm going to define a couple of configurations I'm interested in trying: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define some of the configurations to try\n",
    "configurations_to_try = {\n",
    "    \"ivfflat@lists=10\": (\"ivfflat\", {\"lists\": 10}),\n",
    "    \"ivfflat@lists=50\": (\"ivfflat\", {\"lists\": 50}),\n",
    "    \"ivfflat@lists=100\": (\"ivfflat\", {\"lists\": 100}),\n",
    "}\n",
    "\n",
    "# Define the different values of nearest_neighbors_to_screen to try\n",
    "nearest_neighbor_screening_vals = [1000, 10000, 50000]\n",
    "probes_vals = [1, 4, 10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally: we'll run through each configuration, create the index, and then save the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We're going to store all of the resulting DataFrames in this list\n",
    "approximate_search_query_result_dfs = []\n",
    "query_time_results = {}\n",
    "index_build_time_results = {}\n",
    "\n",
    "# Iterate through each of the configurations in the configurations_to_try dictionary\n",
    "for config_name, config_tuple in configurations_to_try.items():\n",
    "\n",
    "    query_postgres(\n",
    "        \"SET max_parallel_maintenance_workers = 7; -- plus leader\",\n",
    "        engine=engine,\n",
    "        logger=logger,\n",
    "    )\n",
    "    query_postgres(\"SET maintenance_work_mem = '6GB';\", engine=engine, logger=logger)\n",
    "\n",
    "    # Run the create_embeddings_index method\n",
    "    index_build_time_start = time.time()\n",
    "    create_embeddings_index(\n",
    "        index_type=config_tuple[0],\n",
    "        index_build_parameters=config_tuple[1],\n",
    "        distance_metric=\"vector_ip_ops\",\n",
    "    )\n",
    "\n",
    "    # Store the time it took to build the index\n",
    "    index_build_time_results[config_name] = time.time() - index_build_time_start\n",
    "    print(\n",
    "        f\"Index build time for {config_name}: {index_build_time_results[config_name]:.2f} seconds\"\n",
    "    )\n",
    "\n",
    "    # Iterate through each of the different values of probes\n",
    "    cur_config_probes_list = list(probes_vals)\n",
    "\n",
    "    # If the current configuration is not ivfflat, set the probes list to [1]\n",
    "    if config_tuple[0] != \"ivfflat\":\n",
    "        cur_config_probes_list = [1]\n",
    "\n",
    "    for cur_probes_val in probes_vals:\n",
    "\n",
    "        print(f\"\\n\\nRUNNING WITH PROBES = {cur_probes_val}\\n\\n\")\n",
    "\n",
    "        # If the current probes val is larger than the number of lists, skip it\n",
    "        if cur_probes_val > config_tuple[1].get(\"lists\", 0):\n",
    "            continue\n",
    "\n",
    "        # Set the current probes value in the index\n",
    "        query_postgres(\n",
    "            f\"SET ivfflat.probes = {cur_probes_val};\",\n",
    "            engine=engine,\n",
    "            logger=logger,\n",
    "        )\n",
    "\n",
    "        # Iterate through each of the different values of nearest_neighbors_to_screen\n",
    "        for cur_nearest_neighbor_val in nearest_neighbor_screening_vals:\n",
    "\n",
    "            # Iterate through each of the queries and run them in the database\n",
    "            for query in tqdm(queries_to_test):\n",
    "\n",
    "                # Print some information about the current query\n",
    "                print(\n",
    "                    f\"Running query: '{query}' with nearest_neighbors_to_screen={cur_nearest_neighbor_val} and configuration={config_name}\"\n",
    "                )\n",
    "\n",
    "                # Time the query\n",
    "                start_time = time.time()\n",
    "\n",
    "                # Use the neural search for the current query\n",
    "                cur_query_results = neural_search(\n",
    "                    query=query,\n",
    "                    n_videos_to_return=10,\n",
    "                    nearest_neighbors_to_screen=cur_nearest_neighbor_val,\n",
    "                )\n",
    "                query_total_time = time.time() - start_time\n",
    "\n",
    "                # Load the results into a DataFrame\n",
    "                cur_query_results_df = pd.DataFrame.from_records(\n",
    "                    json.loads(cur_query_results)\n",
    "                )\n",
    "\n",
    "                # Add the query to the DataFrame\n",
    "                cur_query_results_df[\"query\"] = query\n",
    "\n",
    "                # Add the nearest_neighbors_to_screen value to the DataFrame\n",
    "                cur_query_results_df[\"nearest_neighbors_to_screen\"] = (\n",
    "                    cur_nearest_neighbor_val\n",
    "                )\n",
    "\n",
    "                # Add the configuration name to the DataFrame\n",
    "                cur_query_results_df[\"configuration\"] = (\n",
    "                    f\"{config_name}_probes={cur_probes_val}\"\n",
    "                )\n",
    "\n",
    "                # Add the query time to the DataFrame\n",
    "                cur_query_results_df[\"query_time\"] = query_total_time\n",
    "\n",
    "                # Add the probes value to the DataFrame\n",
    "                cur_query_results_df[\"probes\"] = cur_probes_val\n",
    "\n",
    "                # Append the results to the list\n",
    "                approximate_search_query_result_dfs.append(cur_query_results_df)\n",
    "\n",
    "# Now, we're going to concatenate the results into a single DataFrame\n",
    "approximate_search_query_results_df = pd.concat(approximate_search_query_result_dfs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Comparing Results**\n",
    "Now that I've got some exact and nearest-neighbor results, I can compare them. The cell below will determine - for every configuration & `nearest_neighbors_to_screen` value - how many results overlapped with the actual nearest neighbors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameterize the results comparison\n",
    "n_top_results_to_compare = 10\n",
    "\n",
    "# We're going to collect records about each query's comparison to the exact search results\n",
    "query_comparison_results_records = []\n",
    "\n",
    "# Iterate through each query, and compare the results of the exact search to the approximate search\n",
    "for query in queries_to_test:\n",
    "\n",
    "    # Get the exact search results for the current query\n",
    "    exact_search_results = exact_search_query_results_df[\n",
    "        exact_search_query_results_df[\"query\"] == query\n",
    "    ]\n",
    "\n",
    "    # Get a ranked list of the exact search results\n",
    "    exact_results_ranked_list = list(exact_search_results[\"url\"])[\n",
    "        :n_top_results_to_compare\n",
    "    ]\n",
    "\n",
    "    # Get the approximate_search_query_results_df for the current query\n",
    "    approximate_search_results = approximate_search_query_results_df[\n",
    "        approximate_search_query_results_df[\"query\"] == query\n",
    "    ]\n",
    "\n",
    "    # Iterate through each of the configurations in the approximate search results\n",
    "    for config_name in approximate_search_results[\"configuration\"].unique():\n",
    "\n",
    "        # Get the approximate search results for the current configuration\n",
    "        cur_config_approximate_search_results = approximate_search_results[\n",
    "            approximate_search_results[\"configuration\"] == config_name\n",
    "        ]\n",
    "\n",
    "        # Iterate through each of the nearest_neighbors_to_screen values\n",
    "        for nearest_neighbors_to_screen in cur_config_approximate_search_results[\n",
    "            \"nearest_neighbors_to_screen\"\n",
    "        ].unique():\n",
    "\n",
    "            # Get the approximate search results for the current nearest_neighbors_to_screen value\n",
    "            cur_nearest_neighbors_to_screen_results = (\n",
    "                cur_config_approximate_search_results[\n",
    "                    cur_config_approximate_search_results[\"nearest_neighbors_to_screen\"]\n",
    "                    == nearest_neighbors_to_screen\n",
    "                ]\n",
    "            )\n",
    "\n",
    "            # Get the ranked list of approximate search results\n",
    "            cur_approx_config_ranked_list = list(\n",
    "                cur_nearest_neighbors_to_screen_results[\"url\"]\n",
    "            )[:n_top_results_to_compare]\n",
    "\n",
    "            # Run the Kendall Tau test\n",
    "            tau, p_value = kendalltau(\n",
    "                exact_results_ranked_list, cur_approx_config_ranked_list\n",
    "            )\n",
    "\n",
    "            # Store this information\n",
    "            query_comparison_results_records.append(\n",
    "                {\n",
    "                    \"query\": query,\n",
    "                    \"configuration\": config_name,\n",
    "                    \"nearest_neighbors_to_screen\": nearest_neighbors_to_screen,\n",
    "                    \"kendall_tau\": tau,\n",
    "                    \"p_value\": p_value,\n",
    "                    \"n_overlap\": len(\n",
    "                        set(exact_results_ranked_list).intersection(\n",
    "                            set(cur_approx_config_ranked_list)\n",
    "                        )\n",
    "                    ),\n",
    "                    \"query_time\": cur_nearest_neighbors_to_screen_results[\n",
    "                        \"query_time\"\n",
    "                    ].max(),\n",
    "                    \"probes\": cur_nearest_neighbors_to_screen_results[\"probes\"].max(),\n",
    "                }\n",
    "            )\n",
    "\n",
    "# Finally, we're going to store the results of the comparison in a DataFrame\n",
    "query_comparison_results_df = pd.DataFrame.from_records(\n",
    "    query_comparison_results_records\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that I've got that, I want to understand: how does the configuration change the `n_overlap`? I'll make a box plot below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.box(\n",
    "    query_comparison_results_df,\n",
    "    x=\"configuration\",\n",
    "    y=\"n_overlap\",\n",
    "    color=\"configuration\",\n",
    "    title=\"Number of Overlapping Results\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In general: this seems to lead me to believe that the IVFFlat algorithm tends to do a bit better job at actually identifying similar results to the exact nearest neighbor search.\n",
    "\n",
    "Let's make the same box plot, but analyzing the Kendall's Tau instead:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.box(\n",
    "    query_comparison_results_df,\n",
    "    x=\"configuration\",\n",
    "    y=\"kendall_tau\",\n",
    "    color=\"configuration\",\n",
    "    title=\"Kendall Tau\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try and plot the effect that the `nearest_neighbors_to_screen` has on the Kendall's Tau:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "configurations_to_include = query_comparison_results_df[\"configuration\"].unique()\n",
    "\n",
    "n_neighbors_effect_on_kendall_tau_df = (\n",
    "    (\n",
    "        query_comparison_results_df[\n",
    "            query_comparison_results_df[\"configuration\"].isin(configurations_to_include)\n",
    "        ]\n",
    "    )\n",
    "    .groupby([\"configuration\", \"nearest_neighbors_to_screen\"])\n",
    "    .agg({\"kendall_tau\": \"mean\"})\n",
    "    .reset_index()\n",
    "    .sort_values(\"nearest_neighbors_to_screen\", ascending=True)\n",
    ")\n",
    "\n",
    "# Use Plotly to create a line plot of the Kendall's Tau by nearest_neighbors_to_screen\n",
    "px.line(\n",
    "    n_neighbors_effect_on_kendall_tau_df,\n",
    "    x=\"nearest_neighbors_to_screen\",\n",
    "    y=\"kendall_tau\",\n",
    "    color=\"configuration\",\n",
    "    title=\"Kendall Tau by nearest_neighbors_to_screen\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_comparison_results_df[query_comparison_results_df[\"configuration\"].str.startswith(\"ivfflat@lists=10_\")].sort_values(\n",
    "    \"n_overlap\", ascending=False\n",
    ").head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
