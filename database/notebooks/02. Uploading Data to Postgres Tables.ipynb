{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Uploading Data to Postgres Tables**\n",
    "Now that I've spent some time initializing the tables, I can upload additional data to the database. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup\n",
    "The cells below will set up the rest of the notebook.\n",
    "\n",
    "I'll start by configuring the kernel: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d:\\data\\programming\\neural-needledrop\\database\n",
      "env: LOG_TO_CONSOLE=True\n",
      "env: LOG_LEVEL=INFO\n",
      "env: TQDM_ENABLED=True\n"
     ]
    }
   ],
   "source": [
    "# Change the working directory \n",
    "%cd ..\n",
    "\n",
    "# Enable the autoreload extension, which will automatically load in new code as it's written\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Set up some envvars\n",
    "%env LOG_TO_CONSOLE=True\n",
    "%env LOG_LEVEL=INFO\n",
    "%env TQDM_ENABLED=True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I'll import some necessary modules:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General import statements\n",
    "import pandas as pd\n",
    "from pandas_gbq import read_gbq\n",
    "from sqlalchemy import create_engine, MetaData\n",
    "from sqlalchemy.orm import sessionmaker, declarative_base\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "from google.cloud import storage\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "import numpy as np\n",
    "\n",
    "# Importing modules custom-built for this project\n",
    "from utils.settings import (\n",
    "    GBQ_PROJECT_ID,\n",
    "    GBQ_DATASET_ID,\n",
    "    POSTGRES_USER,\n",
    "    POSTGRES_PASSWORD,\n",
    "    POSTGRES_HOST,\n",
    "    POSTGRES_PORT,\n",
    "    POSTGRES_DB,\n",
    "    LOG_TO_CONSOLE,\n",
    ")\n",
    "from utils.logging import get_logger\n",
    "from utils.gcs import download_file_from_bucket\n",
    "from utils.postgres import query_postgres, upload_to_table\n",
    "\n",
    "# Set up a logger for this notebook\n",
    "logger = get_logger(\"postgres_notebook\", log_to_console=LOG_TO_CONSOLE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we're going to set up the Postgres engine via SQLAlchemy!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the connection string to the database\n",
    "postgres_connection_string = f\"postgresql://{POSTGRES_USER}:{POSTGRES_PASSWORD}@{POSTGRES_HOST}:{POSTGRES_PORT}/{POSTGRES_DB}\"\n",
    "\n",
    "# Create the connection engine\n",
    "engine = create_engine(postgres_connection_string)\n",
    "metadata = MetaData()\n",
    "session = sessionmaker(bind=engine)()\n",
    "Base = declarative_base()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we're going to set up the Postgres engine via SQLAlchemy!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Downloading Data from GBQ**\n",
    "\n",
    "Before I do anything with `postgres`, I'm just going to download all of the data from GBQ. This will save me some time now (since I can more easily check the Postgres table to understand which data to upload), but I should probably change this in the future to optimize performance & speed. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Determining Data to Upload\n",
    "I need to identify which data is already in each of the `postgres` tables. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine the videos currently in the `video_metadata` table\n",
    "cur_database_video_metadata_df = query_postgres(\n",
    "    \"SELECT id FROM video_metadata\",\n",
    "    engine=engine,\n",
    "    logger=logger,\n",
    ")\n",
    "\n",
    "# Determine the transcriptions currently in the `transcriptions` table\n",
    "cur_database_transcriptions_df = query_postgres(\n",
    "    \"SELECT DISTINCT(url) FROM transcriptions\",\n",
    "    engine=engine,\n",
    "    logger=logger,\n",
    ")\n",
    "\n",
    "# Determine the embeddings currently in the `embeddings` table\n",
    "cur_database_embeddings_df = query_postgres(\n",
    "    \"SELECT DISTINCT(id) FROM embeddings\",\n",
    "    engine=engine,\n",
    "    logger=logger,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, I'm going to upload some temporary tables. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload the `cur_database_video_metadata_df` dataframe to a temporary table in GBQ\n",
    "cur_database_video_metadata_df.to_gbq(\n",
    "    f\"{GBQ_PROJECT_ID}.{GBQ_DATASET_ID}.cur_pg_db_video_metadata\",\n",
    "    if_exists=\"replace\",\n",
    ")\n",
    "\n",
    "# Upload the `cur_database_transcriptions_df` dataframe to a temporary table in GBQ\n",
    "cur_database_transcriptions_df.to_gbq(\n",
    "    f\"{GBQ_PROJECT_ID}.{GBQ_DATASET_ID}.cur_pg_db_transcriptions\",\n",
    "    if_exists=\"replace\",\n",
    ")\n",
    "\n",
    "# Upload the `cur_database_embeddings_df` dataframe to a temporary table in GBQ\n",
    "cur_database_embeddings_df.to_gbq(\n",
    "    f\"{GBQ_PROJECT_ID}.{GBQ_DATASET_ID}.cur_pg_db_embeddings\",\n",
    "    if_exists=\"replace\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **`video_metadata`**\n",
    "The first table is the `video_metadata` table. I'll download that (and some columns from the `enriched_video_metadata` table) for all of the videos that I've transcribed and embedded. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a query that'll grab all of the video metadata from the GBQ database\n",
    "video_metadata_query = f\"\"\"\n",
    "-- This query will select metadata for all of the videos that have transcriptions & embeddings\n",
    "SELECT\n",
    "  video.*,\n",
    "  enriched_video.video_type,\n",
    "  enriched_video.review_score\n",
    "FROM\n",
    "  `{GBQ_PROJECT_ID}.{GBQ_DATASET_ID}.video_metadata` video\n",
    "JOIN\n",
    "  `{GBQ_PROJECT_ID}.{GBQ_DATASET_ID}.enriched_video_metadata` enriched_video\n",
    "ON\n",
    "  video.id = enriched_video.id\n",
    "WHERE\n",
    "  video.url IN (SELECT DISTINCT(url) FROM `{GBQ_PROJECT_ID}.{GBQ_DATASET_ID}.transcriptions`)\n",
    "  AND\n",
    "  video.url IN (SELECT DISTINCT(video_url) AS url FROM `{GBQ_PROJECT_ID}.{GBQ_DATASET_ID}.embeddings`)\n",
    "  AND\n",
    "  video.id NOT IN (SELECT id FROM `{GBQ_PROJECT_ID}.{GBQ_DATASET_ID}.cur_pg_db_video_metadata`)\n",
    "\"\"\"\n",
    "\n",
    "# Execute the above query\n",
    "video_metadata_df = read_gbq(video_metadata_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **`transcriptions`**\n",
    "Next, I'm going to download all of the transcriptions for the videos I'd identified above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare the query that will download all of the relevant rows from the \n",
    "# transcription table\n",
    "transcriptions_query = f\"\"\"\n",
    "SELECT \n",
    "  transcription.url,\n",
    "  transcription.text,\n",
    "  transcription.segment_id,\n",
    "  transcription.segment_seek,\n",
    "  transcription.segment_start,\n",
    "  transcription.segment_end\n",
    "FROM\n",
    "  `{GBQ_PROJECT_ID}.{GBQ_DATASET_ID}.transcriptions` transcription\n",
    "JOIN (\n",
    "  SELECT\n",
    "    video.url\n",
    "  FROM\n",
    "    `neural-needledrop.backend_data.video_metadata` video\n",
    "  WHERE\n",
    "    video.url IN (SELECT DISTINCT(url) FROM `{GBQ_PROJECT_ID}.{GBQ_DATASET_ID}.transcriptions`)\n",
    "    AND\n",
    "    video.url IN (SELECT DISTINCT(video_url) AS url FROM `{GBQ_PROJECT_ID}.{GBQ_DATASET_ID}.embeddings`)\n",
    "    AND\n",
    "    video.id NOT IN (SELECT id FROM `{GBQ_PROJECT_ID}.{GBQ_DATASET_ID}.cur_pg_db_video_metadata`)\n",
    ") video\n",
    "ON\n",
    "  video.url = transcription.url\n",
    "\"\"\"\n",
    "\n",
    "# Execute the above query\n",
    "transcriptions_df = read_gbq(transcriptions_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **`embeddings`**\n",
    "Next up, the `embeddings` table! This one will require a *little* more setup, since we'll need to separately download the embeddings themselves from GCS. (My GBQ dataset only has pointers to each of the GCS URLs.)\n",
    "\n",
    "I'll start by downloading all of the GBQ data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare the query that will download the `embeddings` table\n",
    "embeddings_query = f\"\"\"\n",
    "SELECT \n",
    "  embedding.id,\n",
    "  embedding.video_url AS url,\n",
    "  embedding.embedding_type,\n",
    "  embedding.start_segment,\n",
    "  embedding.end_segment,\n",
    "  embedding.segment_length,\n",
    "  embedding.gcs_uri\n",
    "FROM\n",
    "  `{GBQ_PROJECT_ID}.{GBQ_DATASET_ID}.embeddings` embedding\n",
    "JOIN (\n",
    "  SELECT\n",
    "    video.url\n",
    "  FROM\n",
    "    `{GBQ_PROJECT_ID}.{GBQ_DATASET_ID}.video_metadata` video\n",
    "  WHERE\n",
    "    video.url IN (SELECT DISTINCT(url) FROM `{GBQ_PROJECT_ID}.{GBQ_DATASET_ID}.transcriptions`)\n",
    "    AND\n",
    "    video.url IN (SELECT DISTINCT(video_url) AS url FROM `{GBQ_PROJECT_ID}.{GBQ_DATASET_ID}.embeddings`)\n",
    "    AND\n",
    "    video.id NOT IN (SELECT id FROM `{GBQ_PROJECT_ID}.{GBQ_DATASET_ID}.cur_pg_db_video_metadata`)\n",
    ") video\n",
    "ON\n",
    "  video.url = embedding.video_url\n",
    "GROUP BY\n",
    "  embedding.id,\n",
    "  embedding.video_url,\n",
    "  embedding.embedding_type,\n",
    "  embedding.start_segment,\n",
    "  embedding.end_segment,\n",
    "  embedding.segment_length,\n",
    "  embedding.gcs_uri\n",
    "\"\"\"\n",
    "\n",
    "# Execute the above query\n",
    "# TODO: UNCOMMENT THIS .head(1000) TO GET ALL OF THE EMBEDDINGS\n",
    "embeddings_df = read_gbq(embeddings_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I can delete the temporary tables now! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete each of the cur_pg_db tables\n",
    "read_gbq(f\"DROP TABLE IF EXISTS `{GBQ_PROJECT_ID}.{GBQ_DATASET_ID}.cur_pg_db_video_metadata`\")\n",
    "read_gbq(f\"DROP TABLE IF EXISTS `{GBQ_PROJECT_ID}.{GBQ_DATAST_ID}.cur_pg_db_transcriptions`\")\n",
    "read_gbq(f\"DROP TABLE IF EXISTS `{GBQ_PROJECT_ID}.{GBQ_DATASET_ID}.cur_pg_db_embeddings`\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that I've got all of the embeddings metadata, I can download the embeddings themselves. I'll start by creating a temporary directory to store embeddings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a temporary directory to store the embeddings\n",
    "temp_emb_directory_path = Path(\"temp_embeddings\")\n",
    "temp_emb_directory_path.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "# Remove any files that're already in the directory if it exists\n",
    "for file in temp_emb_directory_path.glob(\"*\"):\n",
    "    file.unlink()\n",
    "\n",
    "# Create a GCS client\n",
    "gcs_client = storage.Client(\n",
    "    project=GBQ_PROJECT_ID\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, I'll iterate through each of the GCS URIs and download them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the list of GCS URIs\n",
    "gcs_uris = embeddings_df[\"gcs_uri\"].unique()\n",
    "\n",
    "def download_embedding(idx_and_uri):\n",
    "    idx, gcs_uri = idx_and_uri\n",
    "    try:\n",
    "        # Parse the GCS URI\n",
    "        split_gcs_uri = gcs_uri.split(\"gs://\")[-1]\n",
    "        bucket_name, file_name = split_gcs_uri.split(\"/\")[0], \"/\".join(\n",
    "            split_gcs_uri.split(\"/\")[1:]\n",
    "        )\n",
    "        \n",
    "        # Download the embedding corresponding with this GCS URI\n",
    "        download_file_from_bucket(\n",
    "            bucket_name=bucket_name,\n",
    "            file_name=file_name,\n",
    "            destination_folder=str(temp_emb_directory_path) + \"/\",\n",
    "            project_id=GBQ_PROJECT_ID,\n",
    "            gcs_client=gcs_client,\n",
    "            logger=logger,\n",
    "        )\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error parsing GCS URI: {e}\")\n",
    "        pass\n",
    "\n",
    "# Use ThreadPoolExecutor to parallelize the download process\n",
    "with ThreadPoolExecutor(max_workers=10) as executor:\n",
    "    futures = {executor.submit(download_embedding, idx_uri): idx_uri for idx_uri in enumerate(gcs_uris)}\n",
    "    for future in tqdm(as_completed(futures), total=len(gcs_uris)):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, I'll load all of the embeddings into RAM. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We're going to store the embeddings in a dictionary, where the key is the\n",
    "# embedding ID and the value is the ndarray of the embedding\n",
    "embeddings = {}\n",
    "for idx, emb_file in tqdm(list(enumerate(list(temp_emb_directory_path.iterdir())))):\n",
    "    try:\n",
    "        # Load in the .npy file as a numpy array\n",
    "        embedding = np.load(emb_file)\n",
    "        \n",
    "        # If the embedding is empty, skip it\n",
    "        # TODO: This is because it seems like a ton of embeddings are \n",
    "        # empty. We should figure out why that is.\n",
    "        if embedding.shape == ():\n",
    "            continue\n",
    "        \n",
    "        # Get the embedding ID\n",
    "        embedding_id = emb_file.stem\n",
    "        \n",
    "        # Add the embedding to the dictionary, storing the list representation\n",
    "        embeddings[embedding_id] = embedding.tolist()\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error loading embedding: {e}\")\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that I've loaded all of the embeddings, I'll delete all of the files in the temporary folder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete all of the files in the temp directory\n",
    "for file in temp_emb_directory_path.glob(\"*\"):\n",
    "    file.unlink()\n",
    "    \n",
    "# Delete the temp directory\n",
    "temp_emb_directory_path.rmdir()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, I'll add the embeddings I've loaded to the embedding DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a \"loaded_embeddings_df\" that has the embeddings loaded in\n",
    "loaded_embeddings_df = embeddings_df.copy()\n",
    "loaded_embeddings_df[\"embedding\"] = loaded_embeddings_df[\"id\"].apply(\n",
    "    lambda x: embeddings.get(x, None)\n",
    ")\n",
    "\n",
    "# Drop any rows where the embedding is None\n",
    "loaded_embeddings_df = loaded_embeddings_df.dropna(subset=[\"embedding\"]).drop_duplicates(\n",
    "    subset=[\"id\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Uploading Data to the Postgres Database\n",
    "Now that I've downloaded all of the data, I'm going to determine which data I need to upload, and then upload it!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Determining Data to Upload\n",
    "I need to identify which data is already in each of the `postgres` tables. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine the videos currently in the `video_metadata` table\n",
    "cur_database_video_metadata_df = query_postgres(\n",
    "    \"SELECT id FROM video_metadata\",\n",
    "    engine=engine,\n",
    "    logger=logger,\n",
    ")\n",
    "\n",
    "# Determine the transcriptions currently in the `transcriptions` table\n",
    "cur_database_transcriptions_df = query_postgres(\n",
    "    \"SELECT DISTINCT(url) FROM transcriptions\",\n",
    "    engine=engine,\n",
    "    logger=logger,\n",
    ")\n",
    "\n",
    "# Determine the embeddings currently in the `embeddings` table\n",
    "cur_database_embeddings_df = query_postgres(\n",
    "    \"SELECT DISTINCT(id) FROM embeddings\",\n",
    "    engine=engine,\n",
    "    logger=logger,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've got the data currently in the database, we'll figure out which files we need to download. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine which rows of the video_metadata_df we need to add to the database\n",
    "video_metadata_df_to_add = video_metadata_df[\n",
    "    ~video_metadata_df[\"id\"].isin(cur_database_video_metadata_df[\"id\"])\n",
    "].copy()\n",
    "\n",
    "# Determine which rows of the transcriptions_df we need to add to the database\n",
    "transcriptions_df_to_add = transcriptions_df[\n",
    "    ~transcriptions_df[\"url\"].isin(cur_database_transcriptions_df[\"url\"])\n",
    "].copy()\n",
    "\n",
    "# Determine which rows of the embeddings_df we need to add to the database\n",
    "embeddings_df_to_add = loaded_embeddings_df[\n",
    "    ~loaded_embeddings_df[\"id\"].isin(cur_database_embeddings_df[\"id\"])\n",
    "].copy()\n",
    "\n",
    "# Log some information about the number of rows we're adding\n",
    "logger.info(\n",
    "    f\"Adding {len(video_metadata_df_to_add)} rows to the video_metadata table.\"\n",
    ")\n",
    "logger.info(\n",
    "    f\"Adding {len(transcriptions_df_to_add)} rows to the transcriptions table.\"\n",
    ")\n",
    "logger.info(\n",
    "    f\"Adding {len(embeddings_df_to_add)} rows to the embeddings table.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uploading Data to Postgres Table\n",
    "Now, we'll upload each of the DataFrames to the Postgres server. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload the video metadata to the database\n",
    "upload_to_table(\n",
    "    video_metadata_df_to_add,\n",
    "    \"video_metadata\",\n",
    "    engine=engine,\n",
    "    logger=logger,\n",
    ")\n",
    "\n",
    "# Upload the transcriptions to the database\n",
    "upload_to_table(\n",
    "    transcriptions_df_to_add,\n",
    "    \"transcriptions\",\n",
    "    engine=engine,\n",
    "    logger=logger,\n",
    ")\n",
    "\n",
    "# Upload the embeddings to the database\n",
    "upload_to_table(\n",
    "    embeddings_df_to_add.drop(columns=[\"gcs_uri\"]),\n",
    "    \"embeddings\",\n",
    "    engine=engine,\n",
    "    logger=logger,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FIXING STUPID SHIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all of the embeddings from the postgres database\n",
    "postgres_embeddings_df = query_postgres(\n",
    "    \"SELECT * FROM embeddings\",\n",
    "    engine=engine,\n",
    "    logger=logger,\n",
    ")\n",
    "\n",
    "# Get all of the transcriptions from the postgres database\n",
    "postgres_transcriptions_df = query_postgres(\n",
    "    \"SELECT * FROM transcriptions\",\n",
    "    engine=engine,\n",
    "    logger=logger,\n",
    ")\n",
    "\n",
    "# Get all of the video metadata from the postgres database\n",
    "postgres_video_metadata_df = query_postgres(\n",
    "    \"SELECT * FROM video_metadata\",\n",
    "    engine=engine,\n",
    "    logger=logger,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the postgres embeddings and GBQ embeddings DataFrames\n",
    "merged_embeddings_df = pd.concat(\n",
    "    [postgres_embeddings_df, embeddings_df], ignore_index=True\n",
    ")\n",
    "\n",
    "# Merge the postgres transcriptions and GBQ transcriptions DataFrames\n",
    "merged_transcriptions_df = pd.concat(\n",
    "    [postgres_transcriptions_df, transcriptions_df], ignore_index=True\n",
    ")\n",
    "\n",
    "# Convert data types in postgres_video_metadata_df to match video_metadata_df\n",
    "postgres_video_metadata_df['length'] = postgres_video_metadata_df['length'].astype('Int64')\n",
    "postgres_video_metadata_df['view_ct'] = postgres_video_metadata_df['view_ct'].astype('Int64')\n",
    "postgres_video_metadata_df['review_score'] = postgres_video_metadata_df['review_score'].astype('Int64')\n",
    "\n",
    "# Convert datetime columns, if necessary (usually, this might not be needed as pandas handles these well)\n",
    "postgres_video_metadata_df['publish_date'] = postgres_video_metadata_df['publish_date'].astype('datetime64[us]')\n",
    "postgres_video_metadata_df['scrape_date'] = postgres_video_metadata_df['scrape_date'].astype('datetime64[us]')\n",
    "\n",
    "# Now try concatenating again\n",
    "merged_video_metadata_df = pd.concat([postgres_video_metadata_df, video_metadata_df], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "UPLOAD AND"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload and replace all of the merged DataFrames\n",
    "merged_video_metadata_df.to_gbq(\n",
    "    f\"{GBQ_PROJECT_ID}.{GBQ_DATASET_ID}.video_metadata\",\n",
    "    if_exists=\"replace\",\n",
    ")\n",
    "\n",
    "merged_transcriptions_df.to_gbq(\n",
    "    f\"{GBQ_PROJECT_ID}.{GBQ_DATASET_ID}.transcriptions\",\n",
    "    if_exists=\"replace\",\n",
    ")\n",
    "\n",
    "merged_embeddings_df.to_gbq(\n",
    "    f\"{GBQ_PROJECT_ID}.{GBQ_DATASET_ID}.embeddings\",\n",
    "    if_exists=\"replace\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.gcs import list_bucket_objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_embeddings_files = list_bucket_objects(\n",
    "    \"neural-needledrop-embeddings\", project_id=GBQ_PROJECT_ID\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse video id, start segment and end segment from each file in all_embeddings_files\n",
    "parsed_embeddings_files = [file.rsplit(\"_\", 2) for file in all_embeddings_files]\n",
    "video_ids = [file[0] for file in parsed_embeddings_files]\n",
    "start_segments = [file[1] for file in parsed_embeddings_files]\n",
    "end_segments = [file[2].split(\".\")[0] for file in parsed_embeddings_files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame({\n",
    "    \"id\": video_ids,\n",
    "    \"video_url\": [\"https://www.youtube.com/watch?v=\" + id for id in video_ids],\n",
    "    \"gcs_uri\": [\"gs://neural-needledrop-embeddings/\" + file + \".npy\" for file in all_embeddings_files],\n",
    "    \"embedding_type\": [\"segment_chunk\"] * len(video_ids),\n",
    "    \"start_segment\": start_segments,\n",
    "    \"end_segment\": end_segments,\n",
    "    \"segment_length\": [int(end) - int(start) for start, end in zip(start_segments, end_segments)]\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>video_url</th>\n",
       "      <th>gcs_uri</th>\n",
       "      <th>embedding_type</th>\n",
       "      <th>start_segment</th>\n",
       "      <th>end_segment</th>\n",
       "      <th>segment_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>--YnsRamkzc</td>\n",
       "      <td>https://www.youtube.com/watch?v=--YnsRamkzc</td>\n",
       "      <td>gs://neural-needledrop-embeddings/--YnsRamkzc_...</td>\n",
       "      <td>segment_chunk</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>--YnsRamkzc</td>\n",
       "      <td>https://www.youtube.com/watch?v=--YnsRamkzc</td>\n",
       "      <td>gs://neural-needledrop-embeddings/--YnsRamkzc_...</td>\n",
       "      <td>segment_chunk</td>\n",
       "      <td>12</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>--YnsRamkzc</td>\n",
       "      <td>https://www.youtube.com/watch?v=--YnsRamkzc</td>\n",
       "      <td>gs://neural-needledrop-embeddings/--YnsRamkzc_...</td>\n",
       "      <td>segment_chunk</td>\n",
       "      <td>15</td>\n",
       "      <td>18</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>--YnsRamkzc</td>\n",
       "      <td>https://www.youtube.com/watch?v=--YnsRamkzc</td>\n",
       "      <td>gs://neural-needledrop-embeddings/--YnsRamkzc_...</td>\n",
       "      <td>segment_chunk</td>\n",
       "      <td>18</td>\n",
       "      <td>21</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>--YnsRamkzc</td>\n",
       "      <td>https://www.youtube.com/watch?v=--YnsRamkzc</td>\n",
       "      <td>gs://neural-needledrop-embeddings/--YnsRamkzc_...</td>\n",
       "      <td>segment_chunk</td>\n",
       "      <td>21</td>\n",
       "      <td>24</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164640</th>\n",
       "      <td>zzmpVAXSd9Y</td>\n",
       "      <td>https://www.youtube.com/watch?v=zzmpVAXSd9Y</td>\n",
       "      <td>gs://neural-needledrop-embeddings/zzmpVAXSd9Y_...</td>\n",
       "      <td>segment_chunk</td>\n",
       "      <td>90</td>\n",
       "      <td>93</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164641</th>\n",
       "      <td>zzmpVAXSd9Y</td>\n",
       "      <td>https://www.youtube.com/watch?v=zzmpVAXSd9Y</td>\n",
       "      <td>gs://neural-needledrop-embeddings/zzmpVAXSd9Y_...</td>\n",
       "      <td>segment_chunk</td>\n",
       "      <td>93</td>\n",
       "      <td>96</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164642</th>\n",
       "      <td>zzmpVAXSd9Y</td>\n",
       "      <td>https://www.youtube.com/watch?v=zzmpVAXSd9Y</td>\n",
       "      <td>gs://neural-needledrop-embeddings/zzmpVAXSd9Y_...</td>\n",
       "      <td>segment_chunk</td>\n",
       "      <td>96</td>\n",
       "      <td>99</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164643</th>\n",
       "      <td>zzmpVAXSd9Y</td>\n",
       "      <td>https://www.youtube.com/watch?v=zzmpVAXSd9Y</td>\n",
       "      <td>gs://neural-needledrop-embeddings/zzmpVAXSd9Y_...</td>\n",
       "      <td>segment_chunk</td>\n",
       "      <td>99</td>\n",
       "      <td>102</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164644</th>\n",
       "      <td>zzmpVAXSd9Y</td>\n",
       "      <td>https://www.youtube.com/watch?v=zzmpVAXSd9Y</td>\n",
       "      <td>gs://neural-needledrop-embeddings/zzmpVAXSd9Y_...</td>\n",
       "      <td>segment_chunk</td>\n",
       "      <td>9</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>164645 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                    video_url  \\\n",
       "0       --YnsRamkzc  https://www.youtube.com/watch?v=--YnsRamkzc   \n",
       "1       --YnsRamkzc  https://www.youtube.com/watch?v=--YnsRamkzc   \n",
       "2       --YnsRamkzc  https://www.youtube.com/watch?v=--YnsRamkzc   \n",
       "3       --YnsRamkzc  https://www.youtube.com/watch?v=--YnsRamkzc   \n",
       "4       --YnsRamkzc  https://www.youtube.com/watch?v=--YnsRamkzc   \n",
       "...             ...                                          ...   \n",
       "164640  zzmpVAXSd9Y  https://www.youtube.com/watch?v=zzmpVAXSd9Y   \n",
       "164641  zzmpVAXSd9Y  https://www.youtube.com/watch?v=zzmpVAXSd9Y   \n",
       "164642  zzmpVAXSd9Y  https://www.youtube.com/watch?v=zzmpVAXSd9Y   \n",
       "164643  zzmpVAXSd9Y  https://www.youtube.com/watch?v=zzmpVAXSd9Y   \n",
       "164644  zzmpVAXSd9Y  https://www.youtube.com/watch?v=zzmpVAXSd9Y   \n",
       "\n",
       "                                                  gcs_uri embedding_type  \\\n",
       "0       gs://neural-needledrop-embeddings/--YnsRamkzc_...  segment_chunk   \n",
       "1       gs://neural-needledrop-embeddings/--YnsRamkzc_...  segment_chunk   \n",
       "2       gs://neural-needledrop-embeddings/--YnsRamkzc_...  segment_chunk   \n",
       "3       gs://neural-needledrop-embeddings/--YnsRamkzc_...  segment_chunk   \n",
       "4       gs://neural-needledrop-embeddings/--YnsRamkzc_...  segment_chunk   \n",
       "...                                                   ...            ...   \n",
       "164640  gs://neural-needledrop-embeddings/zzmpVAXSd9Y_...  segment_chunk   \n",
       "164641  gs://neural-needledrop-embeddings/zzmpVAXSd9Y_...  segment_chunk   \n",
       "164642  gs://neural-needledrop-embeddings/zzmpVAXSd9Y_...  segment_chunk   \n",
       "164643  gs://neural-needledrop-embeddings/zzmpVAXSd9Y_...  segment_chunk   \n",
       "164644  gs://neural-needledrop-embeddings/zzmpVAXSd9Y_...  segment_chunk   \n",
       "\n",
       "       start_segment end_segment  segment_length  \n",
       "0                  0           3               3  \n",
       "1                 12          15               3  \n",
       "2                 15          18               3  \n",
       "3                 18          21               3  \n",
       "4                 21          24               3  \n",
       "...              ...         ...             ...  \n",
       "164640            90          93               3  \n",
       "164641            93          96               3  \n",
       "164642            96          99               3  \n",
       "164643            99         102               3  \n",
       "164644             9          12               3  \n",
       "\n",
       "[164645 rows x 7 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 475.76it/s]\n"
     ]
    }
   ],
   "source": [
    "# Upload the df to the GBQ_PROJECT.GBQ_DATAST.embeddings table\n",
    "df.to_gbq(f\"{GBQ_PROJECT_ID}.{GBQ_DATASET_ID}.embeddings\", if_exists=\"replace\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
