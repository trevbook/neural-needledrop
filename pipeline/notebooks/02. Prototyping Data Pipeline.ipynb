{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Prototyping Data Pipeline**\n",
    "In this notebook, I'm going to be writing a bunch of functions that prototype a data pipeline for this app. Once I write the functions, I'll move them out of this notebook and into a utility file that the main pipeline script can also access. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup\n",
    "The cells below will set up the rest of the notebook.\n",
    "\n",
    "I'll start by configuring the kernel: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d:\\data\\programming\\neural-needledrop\\pipeline\n"
     ]
    }
   ],
   "source": [
    "# Change the working directory \n",
    "%cd ..\n",
    "\n",
    "# Enable the autoreload extension, which will automatically load in new code as it's written\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I'll import some necessary modules:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General import statements\n",
    "import pandas as pd\n",
    "from pytubefix import YouTube, Channel\n",
    "from google.cloud import bigquery\n",
    "import traceback\n",
    "import time\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import pandas_gbq\n",
    "import datetime\n",
    "import uuid\n",
    "from datetime import timedelta\n",
    "from pathlib import Path\n",
    "from google.cloud import storage\n",
    "from google.cloud.exceptions import NotFound\n",
    "import whisper\n",
    "\n",
    "# Importing custom utility functions\n",
    "import utils.gbq as gbq_utils\n",
    "import utils.youtube as youtube_utils\n",
    "import utils.gcs as gcs_utils\n",
    "\n",
    "# Indicate whether or not we want tqdm progress bars\n",
    "tqdm_enabled = True\n",
    "\n",
    "# Set some constants for the project\n",
    "GBQ_PROJECT_ID = \"neural-needledrop\"\n",
    "GBQ_DATASET_ID = \"backend_data\"\n",
    "\n",
    "# Set the pandas_gbq context to the project ID\n",
    "# pandas_gbq.context.project = GBQ_PROJECT_ID"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll also load in a whisper model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in the Whisper model of choice\n",
    "whisper_model_size = \"tiny\"\n",
    "whisper_model = whisper.load_model(whisper_model_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checking GBQ Table\n",
    "The **very** first thing I need to do: check the actual `video_metadata` GBQ table to determine the most recent video I've downloaded. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the query that'll grab the most recent video url\n",
    "most_recent_video_url_query = \"\"\"\n",
    "SELECT\n",
    "  metadata.url\n",
    "FROM\n",
    "  `neural-needledrop.backend_data.video_metadata` metadata\n",
    "ORDER BY\n",
    "  publish_date DESC, scrape_date DESC\n",
    "LIMIT 1\n",
    "\"\"\"\n",
    "\n",
    "# Use pandas-gbq to run the query\n",
    "most_recent_video_url_df = pd.read_gbq(most_recent_video_url_query, project_id=GBQ_PROJECT_ID)\n",
    "\n",
    "# If the length of the dataframe is zero, then we need to set the url to None\n",
    "if len(most_recent_video_url_df) == 0:\n",
    "    most_recent_video_url = None\n",
    "\n",
    "# Otherwise, we can just grab the url from the dataframe\n",
    "else:\n",
    "    most_recent_video_url = most_recent_video_url_df.iloc[0][\"url\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Identifying New Videos\n",
    "The first portion of the pipeline: determining if there are any videos to work with in the first place! \n",
    "\n",
    "I'll start by parameterizing the method: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameterize the identification method\n",
    "video_limit = 1000 # If video_limit is None, then we're going to download information for all of the videos\n",
    "\n",
    "# Define the channel of interest\n",
    "channel_url = \"https://www.youtube.com/c/theneedledrop\"\n",
    "\n",
    "most_recent_video_url = None\n",
    "\n",
    "# Indicate the step size for parsing the videos\n",
    "video_parse_step_size = 350"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that I've got the method scoped out, I'm going to write it. I'll identify the first couple of videos. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_video_urls_from_channel(channel, most_recent_video_url=None, video_limit=None, video_parse_step_size=10):\n",
    "    \"\"\"\n",
    "    Helper method to identify all of the video URLs from a channel.\n",
    "    If `most_recent_video_url` is None, then we're going to download information for all of the videos we can, \n",
    "    all the way up to the `video_limit`. If *that* is None, then we're going to download information for all of the videos.\n",
    "    The `video_parse_step_size` indicates how many videos we're going to parse at a time.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Initialize the video URLs\n",
    "    video_urls = []\n",
    "    \n",
    "    # Initialize the video count\n",
    "    video_count = 0\n",
    "    \n",
    "    # Iterate through the channel's videos until we find the `most_recent_video_url`\n",
    "    while most_recent_video_url not in video_urls:\n",
    "        \n",
    "        # Fetch the video URLs\n",
    "        new_video_urls = channel.video_urls[video_count:video_count+video_parse_step_size]\n",
    "        \n",
    "        # Break out if no new video URLs were found\n",
    "        if len(new_video_urls) == 0:\n",
    "            break\n",
    "        \n",
    "        video_urls.extend(new_video_urls)\n",
    "        \n",
    "        # Update the video count\n",
    "        video_count += video_parse_step_size\n",
    "        \n",
    "        # If we've reached the video limit, then break\n",
    "        if (video_limit is not None and video_count >= video_limit):\n",
    "            break\n",
    "    \n",
    "    # Return the video URLs\n",
    "    return video_urls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This method should function to do what I want. Let's test it: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identified 1050 videos to parse.\n"
     ]
    }
   ],
   "source": [
    "# This is the list of video URLs we're going to parse\n",
    "video_urls_to_parse = get_video_urls_from_channel(\n",
    "    channel=Channel(channel_url),\n",
    "    most_recent_video_url=None,\n",
    "    video_limit=video_limit,\n",
    "    video_parse_step_size=video_parse_step_size,\n",
    ")\n",
    "\n",
    "# If the most_recent_video_url is not None, then we're going to remove all of the videos that come after it\n",
    "try:\n",
    "    if most_recent_video_url is not None:\n",
    "        video_urls_to_parse = video_urls_to_parse[\n",
    "            : video_urls_to_parse.index(most_recent_video_url)\n",
    "        ]\n",
    "    else:\n",
    "        pass\n",
    "# If we run into an error, then we're going to print out the traceback\n",
    "except Exception as e:\n",
    "    traceback.print_exc()\n",
    "\n",
    "# Print some information about the video URLs we're going to parse\n",
    "print(f\"Identified {len(video_urls_to_parse)} videos to parse.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing Already Parsed Videos\n",
    "We're going to upload a temporary table with all of the video URLs to GBQ. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "# Create a DataFrame from the video URLs\n",
    "video_urls_to_parse_df = pd.DataFrame(video_urls_to_parse, columns=[\"url\"])\n",
    "\n",
    "# Create a temporary table in GBQ\n",
    "temporary_table_name = gbq_utils.create_temporary_table_in_gbq(\n",
    "    dataframe=video_urls_to_parse_df,\n",
    "    project_id=GBQ_PROJECT_ID,\n",
    "    dataset_name=GBQ_DATASET_ID,\n",
    "    table_name=\"temporary_video_urls_to_parse\",\n",
    "    if_exists=\"replace\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this temporary table in hand, we'll query GBQ to figure out the *actual* videos to download. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the query to identify the videos that we need to parse\n",
    "actual_videos_to_parse_query = f\"\"\"\n",
    "SELECT\n",
    "  temp_urls.url\n",
    "FROM\n",
    "  `{temporary_table_name}` temp_urls\n",
    "LEFT JOIN\n",
    "  `backend_data.video_metadata` metadata\n",
    "ON\n",
    "  metadata.url = temp_urls.url\n",
    "WHERE\n",
    "  metadata.id IS NULL\n",
    "\"\"\"\n",
    "\n",
    "# Execute the query\n",
    "actual_videos_to_parse_df = pd.read_gbq(\n",
    "    actual_videos_to_parse_query, project_id=GBQ_PROJECT_ID\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, some cleanup: setting the `actual_videos_to_parse_df` contents to the video_urls_to_parse, and deleting the temporary table. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After filtering out videos that have already been parsed, we have 650 videos to parse.\n",
      "Table backend_data:temporary_video_urls_to_parse deleted.\n"
     ]
    }
   ],
   "source": [
    "# Print some information about the videos we're going to parse\n",
    "print(f\"After filtering out videos that have already been parsed, we have {len(actual_videos_to_parse_df)} videos to parse.\")\n",
    "\n",
    "# Overriding the video_urls_to_parse with the contents of the actual_videos_to_parse_df\n",
    "video_urls_to_parse = list(actual_videos_to_parse_df[\"url\"])\n",
    "\n",
    "# Use the gbq_utils to delete the temporary table\n",
    "temp_table_project_id, temp_table_dataset_id, temp_table_name = temporary_table_name.split(\".\")\n",
    "gbq_utils.delete_table(\n",
    "    project_id=temp_table_project_id,\n",
    "    dataset_id=temp_table_dataset_id,\n",
    "    table_id=temp_table_name,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Downloading Video Metadata\n",
    "Below, I'm going to define a method that'll download a video's metadata. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_metadata_from_video(video_url):\n",
    "    \"\"\"\n",
    "    This method will parse a dictionary containing metadata from a video, given its URL.\n",
    "    \"\"\"\n",
    "\n",
    "    # Create a video object\n",
    "    video = YouTube(video_url)\n",
    "\n",
    "    # Keep a dictionary to keep track of the metadata we're interested in\n",
    "    video_metadata_dict = {}\n",
    "\n",
    "    # We'll wrap this in a try/except block so that we can catch any errors that occur\n",
    "    try:\n",
    "        # Parse the `videoDetails` from the video; this contains a lot of the metadata we're interested in\n",
    "        vid_info_dict = video.vid_info\n",
    "        video_info_dict = vid_info_dict.get(\"videoDetails\")\n",
    "\n",
    "    # If we run into an Exception this early on, we'll raise an Exception\n",
    "    except Exception as e:\n",
    "        raise Exception(\n",
    "            f\"Error parsing video metadata for video {video_url}: '{e}'\\nTraceback is as follows:\\n{traceback.format_exc()}\"\n",
    "        )\n",
    "\n",
    "    # Extract different pieces of the video metadata\n",
    "    video_metadata_dict[\"id\"] = video_info_dict.get(\"videoId\")\n",
    "    video_metadata_dict[\"title\"] = video_info_dict.get(\"title\")\n",
    "    video_metadata_dict[\"length\"] = video_info_dict.get(\"lengthSeconds\")\n",
    "    video_metadata_dict[\"channel_id\"] = video_info_dict.get(\"channelId\")\n",
    "    video_metadata_dict[\"channel_name\"] = video_info_dict.get(\"author\")\n",
    "    video_metadata_dict[\"short_description\"] = video_info_dict.get(\"shortDescription\")\n",
    "    video_metadata_dict[\"view_ct\"] = video_info_dict.get(\"viewCount\")\n",
    "    video_metadata_dict[\"url\"] = video_info_dict.get(\"video_url\")\n",
    "    video_metadata_dict[\"small_thumbnail_url\"] = (\n",
    "        video_info_dict.get(\"thumbnail\").get(\"thumbnails\")[0].get(\"url\")\n",
    "    )\n",
    "    video_metadata_dict[\"large_thumbnail_url\"] = (\n",
    "        video_info_dict.get(\"thumbnail\").get(\"thumbnails\")[-1].get(\"url\")\n",
    "    )\n",
    "\n",
    "    # Try and extract the the publish_date\n",
    "    try:\n",
    "        publish_date = video.publish_date\n",
    "        video_metadata_dict[\"publish_date\"] = publish_date\n",
    "    except:\n",
    "        video_metadata_dict[\"publish_date\"] = None\n",
    "\n",
    "    # Try and extract the full description\n",
    "    try:\n",
    "        full_description = video.description\n",
    "        video_metadata_dict[\"description\"] = full_description\n",
    "    except:\n",
    "        video_metadata_dict[\"description\"] = None\n",
    "    \n",
    "    # Use datetime to get the scrape_date (the current datetime)\n",
    "    video_metadata_dict[\"scrape_date\"] = datetime.datetime.now()\n",
    "    \n",
    "    # Add the url to the video_metadata_dict\n",
    "    video_metadata_dict[\"url\"] = video_url\n",
    "\n",
    "    # Finally, return the video metadata dictionary\n",
    "    return video_metadata_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now: we'll need to iterate through each of the videos and download their metadata. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 650/650 [2:39:19<00:00, 14.71s/it]  \n"
     ]
    }
   ],
   "source": [
    "# Parameterize the video metadata parsing\n",
    "time_to_sleep_between_parsing = 5\n",
    "sleep_randomization_factor = 3.5\n",
    "\n",
    "# We'll iterate through each of the videos in the list and parse their metadata\n",
    "video_metadata_dicts_by_video_url = {}\n",
    "for video_url in tqdm(video_urls_to_parse, disable=not tqdm_enabled):\n",
    "    \n",
    "    # We'll wrap this in a try/except block so that we can catch any errors that occur\n",
    "    try:\n",
    "        # Parse the metadata from the video\n",
    "        video_metadata_dict = parse_metadata_from_video(video_url)\n",
    "        \n",
    "        # Add the video metadata dictionary to the dictionary of video metadata dictionaries\n",
    "        video_metadata_dicts_by_video_url[video_url] = video_metadata_dict\n",
    "        \n",
    "        # Sleep for a random amount of time\n",
    "        time_to_sleep = random.uniform(time_to_sleep_between_parsing, time_to_sleep_between_parsing + (sleep_randomization_factor * time_to_sleep_between_parsing))\n",
    "        time.sleep(time_to_sleep)\n",
    "    \n",
    "    # If we run into an Exception, then we'll print out the traceback\n",
    "    except Exception as e:\n",
    "        traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Storing the Metadata\n",
    "Now that I've downloaded some metadata about different videos, I need to store it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 650 row(s) into backend_data:video_metadata.\n"
     ]
    }
   ],
   "source": [
    "# Create a list of the rows to add to the table\n",
    "rows_to_add = [val for val in video_metadata_dicts_by_video_url.values()]\n",
    "\n",
    "# Add the rows to the table\n",
    "gbq_utils.add_rows_to_table(\n",
    "    project_id=GBQ_PROJECT_ID,\n",
    "    dataset_id=GBQ_DATASET_ID,\n",
    "    table_id=\"video_metadata\",\n",
    "    rows=rows_to_add   \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Downloading Video Audio\n",
    "Next up, I need to download some video audio. This one probably needs to go a lot slower than the metadata fetching ðŸ˜…"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Determining Audio to Download\n",
    "I need to check with GBQ to see if there are any videos that I need to download. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameterize the query\n",
    "n_max_video_urls = 50\n",
    "\n",
    "# The query below will determine which videos we need to download audio for\n",
    "videos_for_audio_parsing_query = f\"\"\"\n",
    "SELECT\n",
    "  video.url\n",
    "FROM\n",
    "  `backend_data.video_metadata` video\n",
    "LEFT JOIN\n",
    "  `backend_data.audio` audio\n",
    "ON\n",
    "  audio.video_url = video.url\n",
    "WHERE\n",
    "  audio.audio_gcs_uri IS NULL\n",
    "LIMIT {n_max_video_urls}\n",
    "\"\"\"\n",
    "\n",
    "# Execute the query\n",
    "videos_for_audio_parsing_df = pd.read_gbq(\n",
    "    videos_for_audio_parsing_query, project_id=GBQ_PROJECT_ID\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downloading Audio\n",
    "Next, I'm going to use `pytube` to download the audio of these videos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [01:48<00:00,  2.17s/it]\n"
     ]
    }
   ],
   "source": [
    "# Parameterize the download\n",
    "time_to_sleep_between_downloads = 25\n",
    "sleep_randomization_factor = 3.5\n",
    "download_directory = Path(\"temp_data/\")\n",
    "\n",
    "# Iterate through the videos and download their audio\n",
    "for video_url in tqdm(videos_for_audio_parsing_df[\"url\"], disable=not tqdm_enabled):\n",
    "    # We'll wrap this in a try/except block so that we can catch any errors that occur\n",
    "    try:\n",
    "        # Download the audio from the video\n",
    "        youtube_utils.download_audio_from_video(\n",
    "            video_url=video_url, data_folder_path=download_directory\n",
    "        )\n",
    "\n",
    "    # If we run into an Exception, then we'll print out the traceback\n",
    "    except Exception as e:\n",
    "        traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uploading Audio to GCS\n",
    "Now that I've downloaded the audio, I need to upload it to GCS. \n",
    "\n",
    "I'll start by creating the bucket if it doesn't exist:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bucket neural-needledrop.neural-needledrop-audio deleted\n",
      "Bucket neural-needledrop.neural-needledrop-audio created\n"
     ]
    }
   ],
   "source": [
    "# Make sure that the neural-needledrop-audio bucket exists\n",
    "gcs_utils.create_bucket(\n",
    "    \"neural-needledrop-audio\", project_id=GBQ_PROJECT_ID, delete_if_exists=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next: upload all of the audio. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File temp_data\\Gwtat22jkig.mp3 uploaded to neural-needledrop.neural-needledrop-audio\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 41/50 [09:58<02:03, 13.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1 row(s) into backend_data:audio.\n",
      "Found a bucket named neural-needledrop-audio in project neural-needledrop.\n",
      "Uploading file JmhWyeGHz-k.mp3 to neural-needledrop.neural-needledrop-audio...\n",
      "File temp_data\\JmhWyeGHz-k.mp3 uploaded to neural-needledrop.neural-needledrop-audio\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 42/50 [10:15<01:59, 14.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1 row(s) into backend_data:audio.\n",
      "Found a bucket named neural-needledrop-audio in project neural-needledrop.\n",
      "Uploading file m9NrCOoOpUw.mp3 to neural-needledrop.neural-needledrop-audio...\n",
      "File temp_data\\m9NrCOoOpUw.mp3 uploaded to neural-needledrop.neural-needledrop-audio\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 43/50 [10:27<01:37, 13.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1 row(s) into backend_data:audio.\n",
      "Found a bucket named neural-needledrop-audio in project neural-needledrop.\n",
      "Uploading file IkWLUgl8W9E.mp3 to neural-needledrop.neural-needledrop-audio...\n",
      "File temp_data\\IkWLUgl8W9E.mp3 uploaded to neural-needledrop.neural-needledrop-audio\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 44/50 [10:41<01:23, 13.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1 row(s) into backend_data:audio.\n",
      "Found a bucket named neural-needledrop-audio in project neural-needledrop.\n",
      "Uploading file S28rYHXVbYg.mp3 to neural-needledrop.neural-needledrop-audio...\n",
      "File temp_data\\S28rYHXVbYg.mp3 uploaded to neural-needledrop.neural-needledrop-audio\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 45/50 [11:04<01:22, 16.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1 row(s) into backend_data:audio.\n",
      "Found a bucket named neural-needledrop-audio in project neural-needledrop.\n",
      "Uploading file EOphU_IUBNU.mp3 to neural-needledrop.neural-needledrop-audio...\n",
      "File temp_data\\EOphU_IUBNU.mp3 uploaded to neural-needledrop.neural-needledrop-audio\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 46/50 [11:16<01:01, 15.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1 row(s) into backend_data:audio.\n",
      "Found a bucket named neural-needledrop-audio in project neural-needledrop.\n",
      "Uploading file fx7de5AojVk.mp3 to neural-needledrop.neural-needledrop-audio...\n",
      "File temp_data\\fx7de5AojVk.mp3 uploaded to neural-needledrop.neural-needledrop-audio\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 47/50 [11:29<00:43, 14.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1 row(s) into backend_data:audio.\n",
      "Found a bucket named neural-needledrop-audio in project neural-needledrop.\n",
      "Uploading file YVHThYHhmcc.mp3 to neural-needledrop.neural-needledrop-audio...\n",
      "File temp_data\\YVHThYHhmcc.mp3 uploaded to neural-needledrop.neural-needledrop-audio\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 48/50 [11:44<00:29, 14.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1 row(s) into backend_data:audio.\n",
      "Found a bucket named neural-needledrop-audio in project neural-needledrop.\n",
      "Uploading file VgZkcUA3xko.mp3 to neural-needledrop.neural-needledrop-audio...\n",
      "File temp_data\\VgZkcUA3xko.mp3 uploaded to neural-needledrop.neural-needledrop-audio\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 49/50 [11:56<00:13, 13.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1 row(s) into backend_data:audio.\n",
      "Found a bucket named neural-needledrop-audio in project neural-needledrop.\n",
      "Uploading file eNdoI_lKA78.mp3 to neural-needledrop.neural-needledrop-audio...\n",
      "File temp_data\\eNdoI_lKA78.mp3 uploaded to neural-needledrop.neural-needledrop-audio\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [12:09<00:00, 14.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1 row(s) into backend_data:audio.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Parameterize the audio upload process\n",
    "delete_files_after_upload = True\n",
    "\n",
    "# Iterate through all of the video urls in the videos_for_audio_parsing_df\n",
    "for row in tqdm(\n",
    "    list(videos_for_audio_parsing_df.itertuples()), disable=not tqdm_enabled\n",
    "):\n",
    "    # We'll wrap this in a try/except block so that we can catch any errors that occur\n",
    "    try:\n",
    "        # Get the video url\n",
    "        video_url = row.url\n",
    "\n",
    "        # Get the video id\n",
    "        video_id = video_url.split(\"watch?v=\")[-1]\n",
    "\n",
    "        # Get the path to the audio file\n",
    "        audio_file_path = download_directory / f\"{video_id}.m4a\"\n",
    "\n",
    "        # Check to see if this file exists\n",
    "        if not Path(audio_file_path).exists():\n",
    "            # If it doesn't exist, then we'll continue. Print out a warning\n",
    "            print(f\"Warning: {audio_file_path} does not exist. Skipping...\")\n",
    "            continue\n",
    "\n",
    "        # Get the GCS URI\n",
    "        gcs_uri = f\"neural-needledrop-audio\"\n",
    "\n",
    "        # Upload the audio file to GCS\n",
    "        audio_file_path_str = str(audio_file_path)\n",
    "\n",
    "        # Convert the audio file to .mp3 using youtube_utils\n",
    "        youtube_utils.convert_m4a_to_mp3(\n",
    "            input_file_path=audio_file_path_str,\n",
    "            output_file_path=audio_file_path_str.replace(\".m4a\", \".mp3\"),\n",
    "        )\n",
    "\n",
    "        # Remove the .m4a file\n",
    "        audio_file_path.unlink()\n",
    "\n",
    "        # Update the audio_file_path_str\n",
    "        audio_file_path = Path(audio_file_path_str.replace(\".m4a\", \".mp3\"))\n",
    "        audio_file_path_str = str(audio_file_path)\n",
    "\n",
    "        gcs_utils.upload_file_to_bucket(\n",
    "            file_path=audio_file_path_str,\n",
    "            bucket_name=gcs_uri,\n",
    "            project_id=GBQ_PROJECT_ID,\n",
    "        )\n",
    "\n",
    "        # Create a dictionary to store the audio metadata\n",
    "        audio_metadata_dict = {\n",
    "            \"video_url\": video_url,\n",
    "            \"audio_gcs_uri\": f\"gs://{gcs_uri}/{audio_file_path.name}\",\n",
    "            \"scrape_date\": datetime.datetime.now(),\n",
    "        }\n",
    "\n",
    "        # Add the audio metadata to the table\n",
    "        try:\n",
    "            gbq_utils.add_rows_to_table(\n",
    "                project_id=GBQ_PROJECT_ID,\n",
    "                dataset_id=GBQ_DATASET_ID,\n",
    "                table_id=\"audio\",\n",
    "                rows=[audio_metadata_dict],\n",
    "            )\n",
    "        except NotFound:\n",
    "            gbq_utils.generate_audio_table(\n",
    "                project_id=GBQ_PROJECT_ID,\n",
    "                dataset_id=GBQ_DATASET_ID,\n",
    "                delete_if_exists=False,\n",
    "            )\n",
    "            gbq_utils.add_rows_to_table(\n",
    "                project_id=GBQ_PROJECT_ID,\n",
    "                dataset_id=GBQ_DATASET_ID,\n",
    "                table_id=\"audio\",\n",
    "                rows=[audio_metadata_dict],\n",
    "            )\n",
    "\n",
    "        # Delete the audio file if delete_files_after_upload\n",
    "        if delete_files_after_upload:\n",
    "            audio_file_path.unlink()\n",
    "\n",
    "    # If we run into an Exception, then we'll print out the traceback\n",
    "    except Exception as e:\n",
    "        traceback.print_exc()\n",
    "\n",
    "# If we're deleting the files after upload, then we'll delete the download_directory\n",
    "if delete_files_after_upload:\n",
    "    Path(download_directory).rmdir()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, a super quick fix that I ought to handle: I'm going to deduplicate the `backend_data.audio` table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|\u001b[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\u001b[0m|\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_url</th>\n",
       "      <th>audio_gcs_uri</th>\n",
       "      <th>scrape_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.youtube.com/watch?v=b33ZjsTHVXU</td>\n",
       "      <td>gs://neural-needledrop-audio/b33ZjsTHVXU.m4a</td>\n",
       "      <td>2024-01-06 10:21:18.066085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.youtube.com/watch?v=LwbUvvxf2I8</td>\n",
       "      <td>gs://neural-needledrop-audio/LwbUvvxf2I8.m4a</td>\n",
       "      <td>2024-01-06 13:41:32.128619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://www.youtube.com/watch?v=VIsFCth2IHo</td>\n",
       "      <td>gs://neural-needledrop-audio/VIsFCth2IHo.m4a</td>\n",
       "      <td>2024-01-06 13:41:54.614713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://www.youtube.com/watch?v=ImYGdMBWLFw</td>\n",
       "      <td>gs://neural-needledrop-audio/ImYGdMBWLFw.m4a</td>\n",
       "      <td>2024-01-06 13:43:48.034852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.youtube.com/watch?v=m99lkzqB-E0</td>\n",
       "      <td>gs://neural-needledrop-audio/m99lkzqB-E0.m4a</td>\n",
       "      <td>2024-01-06 13:45:23.876181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>https://www.youtube.com/watch?v=xaNzs6IL3pk</td>\n",
       "      <td>gs://neural-needledrop-audio/xaNzs6IL3pk.m4a</td>\n",
       "      <td>2024-01-06 10:16:42.185417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>https://www.youtube.com/watch?v=hAx_VUHss9w</td>\n",
       "      <td>gs://neural-needledrop-audio/hAx_VUHss9w.m4a</td>\n",
       "      <td>2024-01-06 13:44:41.678088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>https://www.youtube.com/watch?v=GElu5cR8XOU</td>\n",
       "      <td>gs://neural-needledrop-audio/GElu5cR8XOU.m4a</td>\n",
       "      <td>2024-01-06 13:39:45.842374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>https://www.youtube.com/watch?v=N2XsYgp6Z8w</td>\n",
       "      <td>gs://neural-needledrop-audio/N2XsYgp6Z8w.m4a</td>\n",
       "      <td>2024-01-06 13:42:50.046260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>https://www.youtube.com/watch?v=eVog1CY1oTM</td>\n",
       "      <td>gs://neural-needledrop-audio/eVog1CY1oTM.m4a</td>\n",
       "      <td>2024-01-06 13:36:14.928173</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>67 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      video_url  \\\n",
       "0   https://www.youtube.com/watch?v=b33ZjsTHVXU   \n",
       "1   https://www.youtube.com/watch?v=LwbUvvxf2I8   \n",
       "2   https://www.youtube.com/watch?v=VIsFCth2IHo   \n",
       "3   https://www.youtube.com/watch?v=ImYGdMBWLFw   \n",
       "4   https://www.youtube.com/watch?v=m99lkzqB-E0   \n",
       "..                                          ...   \n",
       "62  https://www.youtube.com/watch?v=xaNzs6IL3pk   \n",
       "63  https://www.youtube.com/watch?v=hAx_VUHss9w   \n",
       "64  https://www.youtube.com/watch?v=GElu5cR8XOU   \n",
       "65  https://www.youtube.com/watch?v=N2XsYgp6Z8w   \n",
       "66  https://www.youtube.com/watch?v=eVog1CY1oTM   \n",
       "\n",
       "                                   audio_gcs_uri                scrape_date  \n",
       "0   gs://neural-needledrop-audio/b33ZjsTHVXU.m4a 2024-01-06 10:21:18.066085  \n",
       "1   gs://neural-needledrop-audio/LwbUvvxf2I8.m4a 2024-01-06 13:41:32.128619  \n",
       "2   gs://neural-needledrop-audio/VIsFCth2IHo.m4a 2024-01-06 13:41:54.614713  \n",
       "3   gs://neural-needledrop-audio/ImYGdMBWLFw.m4a 2024-01-06 13:43:48.034852  \n",
       "4   gs://neural-needledrop-audio/m99lkzqB-E0.m4a 2024-01-06 13:45:23.876181  \n",
       "..                                           ...                        ...  \n",
       "62  gs://neural-needledrop-audio/xaNzs6IL3pk.m4a 2024-01-06 10:16:42.185417  \n",
       "63  gs://neural-needledrop-audio/hAx_VUHss9w.m4a 2024-01-06 13:44:41.678088  \n",
       "64  gs://neural-needledrop-audio/GElu5cR8XOU.m4a 2024-01-06 13:39:45.842374  \n",
       "65  gs://neural-needledrop-audio/N2XsYgp6Z8w.m4a 2024-01-06 13:42:50.046260  \n",
       "66  gs://neural-needledrop-audio/eVog1CY1oTM.m4a 2024-01-06 13:36:14.928173  \n",
       "\n",
       "[67 rows x 3 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This query will deduplicate the audio table\n",
    "deduplicate_audio_table_query = f\"\"\"\n",
    "CREATE OR REPLACE TABLE `{GBQ_PROJECT_ID}.{GBQ_DATASET_ID}.audio` AS (\n",
    "    SELECT\n",
    "        video_url,\n",
    "        audio_gcs_uri,\n",
    "        scrape_date\n",
    "    FROM (\n",
    "        SELECT\n",
    "            *,\n",
    "            ROW_NUMBER() OVER (PARTITION BY video_url ORDER BY scrape_date DESC) AS row_num\n",
    "        FROM\n",
    "            `{GBQ_PROJECT_ID}.{GBQ_DATASET_ID}.audio`\n",
    "    ) ordered_table\n",
    "    WHERE\n",
    "        ordered_table.row_num = 1\n",
    ")\n",
    "\"\"\"\n",
    "\n",
    "# Execute the query\n",
    "pandas_gbq.read_gbq(deduplicate_audio_table_query, project_id=GBQ_PROJECT_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transcribing Audio with Whisper\n",
    "Now that I've downloaded some audio, I need to figure out what needs to be transcribed. I can do that by checking the `audio` and `transcriptions` table. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This query will determine all of the videos we need to transcribe\n",
    "videos_for_transcription_query = f\"\"\"\n",
    "SELECT\n",
    "  DISTINCT(audio.video_url) AS url,\n",
    "  audio.audio_gcr_uri\n",
    "FROM\n",
    "  `backend_data.audio` audio \n",
    "LEFT JOIN\n",
    "  `backend_data.transcriptions` transcript\n",
    "ON\n",
    "  audio.video_url = transcript.url\n",
    "WHERE\n",
    "  transcript.created_at IS NULL\n",
    "\"\"\"\n",
    "\n",
    "# Execute the query\n",
    "videos_for_transcription_df = pd.read_gbq(\n",
    "    videos_for_transcription_query, project_id=GBQ_PROJECT_ID\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, with all of the audio specified, we need to try and download it from `GCS`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/17 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found a bucket named neural-needledrop-audio in project neural-needledrop.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|â–Œ         | 1/17 [00:01<00:28,  1.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File 8un7EwrKW0Y.mp3 downloaded from neural-needledrop.neural-needledrop-audio to temp_data/\n",
      "Found a bucket named neural-needledrop-audio in project neural-needledrop.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|â–ˆâ–        | 2/17 [00:03<00:27,  1.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File KAedi0Mtfj4.mp3 downloaded from neural-needledrop.neural-needledrop-audio to temp_data/\n",
      "Found a bucket named neural-needledrop-audio in project neural-needledrop.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|â–ˆâ–Š        | 3/17 [00:05<00:27,  1.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File NU8gDMotlP4.mp3 downloaded from neural-needledrop.neural-needledrop-audio to temp_data/\n",
      "Found a bucket named neural-needledrop-audio in project neural-needledrop.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|â–ˆâ–ˆâ–Ž       | 4/17 [00:07<00:25,  1.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File G3xgXi6VeXU.mp3 downloaded from neural-needledrop.neural-needledrop-audio to temp_data/\n",
      "Found a bucket named neural-needledrop-audio in project neural-needledrop.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|â–ˆâ–ˆâ–‰       | 5/17 [00:09<00:23,  1.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File _7gS3LgWNKw.mp3 downloaded from neural-needledrop.neural-needledrop-audio to temp_data/\n",
      "Found a bucket named neural-needledrop-audio in project neural-needledrop.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 6/17 [00:11<00:20,  1.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File UTSdgU3dZco.mp3 downloaded from neural-needledrop.neural-needledrop-audio to temp_data/\n",
      "Found a bucket named neural-needledrop-audio in project neural-needledrop.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 7/17 [00:13<00:19,  1.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File PlloTwEBBE8.mp3 downloaded from neural-needledrop.neural-needledrop-audio to temp_data/\n",
      "Found a bucket named neural-needledrop-audio in project neural-needledrop.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 8/17 [00:15<00:16,  1.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File b33ZjsTHVXU.mp3 downloaded from neural-needledrop.neural-needledrop-audio to temp_data/\n",
      "Found a bucket named neural-needledrop-audio in project neural-needledrop.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 9/17 [00:16<00:15,  1.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File 3CDeF0DViao.mp3 downloaded from neural-needledrop.neural-needledrop-audio to temp_data/\n",
      "Found a bucket named neural-needledrop-audio in project neural-needledrop.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 10/17 [00:18<00:13,  1.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File sGUKtWa7lVg.mp3 downloaded from neural-needledrop.neural-needledrop-audio to temp_data/\n",
      "Found a bucket named neural-needledrop-audio in project neural-needledrop.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 11/17 [00:20<00:10,  1.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File 2eftEUAmNZQ.mp3 downloaded from neural-needledrop.neural-needledrop-audio to temp_data/\n",
      "Found a bucket named neural-needledrop-audio in project neural-needledrop.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 12/17 [00:22<00:08,  1.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File W_Yu9j3AEXQ.mp3 downloaded from neural-needledrop.neural-needledrop-audio to temp_data/\n",
      "Found a bucket named neural-needledrop-audio in project neural-needledrop.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 13/17 [00:24<00:07,  1.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File DoWlDA-GKIQ.mp3 downloaded from neural-needledrop.neural-needledrop-audio to temp_data/\n",
      "Found a bucket named neural-needledrop-audio in project neural-needledrop.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 14/17 [00:26<00:05,  1.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File xaNzs6IL3pk.mp3 downloaded from neural-needledrop.neural-needledrop-audio to temp_data/\n",
      "Found a bucket named neural-needledrop-audio in project neural-needledrop.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 15/17 [00:28<00:03,  1.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File 3iaoQarq9ZA.mp3 downloaded from neural-needledrop.neural-needledrop-audio to temp_data/\n",
      "Found a bucket named neural-needledrop-audio in project neural-needledrop.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 16/17 [00:29<00:01,  1.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File dCK78Czmym0.mp3 downloaded from neural-needledrop.neural-needledrop-audio to temp_data/\n",
      "Found a bucket named neural-needledrop-audio in project neural-needledrop.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:31<00:00,  1.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File _PDzVzOG4nw.mp3 downloaded from neural-needledrop.neural-needledrop-audio to temp_data/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Iterate through all of the video urls in the videos_for_transcription_df\n",
    "for row in tqdm(\n",
    "    list(videos_for_transcription_df.itertuples()), disable=not tqdm_enabled\n",
    "):\n",
    "    # Parse the GCS URI\n",
    "    split_gcs_uri = row.audio_gcr_uri.split(\"gs://\")[-1]\n",
    "    bucket_name, file_name = split_gcs_uri.split(\"/\")[0], \"/\".join(\n",
    "        split_gcs_uri.split(\"/\")[1:]\n",
    "    )\n",
    "\n",
    "    # Download the audio\n",
    "    gcs_utils.download_file_from_bucket(\n",
    "        bucket_name=bucket_name,\n",
    "        file_name=file_name,\n",
    "        destination_folder=\"temp_data/\",\n",
    "        project_id=GBQ_PROJECT_ID,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [17:24<00:00, 61.42s/it]\n"
     ]
    }
   ],
   "source": [
    "# We'll store the audio metadata in a dictionary\n",
    "audio_metadata_dict_by_video_url = {}\n",
    "\n",
    "# Iterate through each of the files in the `temp_data` directory and transcribe them\n",
    "for child_file in tqdm(list(Path(\"temp_data/\").iterdir()), disable=not tqdm_enabled):\n",
    "    try:\n",
    "        if child_file.suffix != \".mp3\":\n",
    "            continue\n",
    "\n",
    "        # Extract some data about the file\n",
    "        video_url = f\"https://www.youtube.com/watch?v={child_file.stem}\"\n",
    "        video_id = child_file.stem\n",
    "\n",
    "        # Use whisper to transcribe the audio\n",
    "        whisper_transcription = whisper_model.transcribe(str(child_file), fp16=False)\n",
    "\n",
    "        # Store the transcription in the audio_metadata_dict_by_video_url\n",
    "        audio_metadata_dict_by_video_url[video_url] = whisper_transcription\n",
    "    except Exception as e:\n",
    "        raise Exception(\n",
    "            f\"Error getting audio file path for video {video_url}: '{e}'\\nTraceback is as follows:\\n{traceback.format_exc()}\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uploading Transcription to GBQ\n",
    "Now that I've transcribed all of these videos, I'm going to upload the transcriptions to GBQ. \n",
    "\n",
    "First, I'll transform the DataFrame to add some needed data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame from the audio_metadata_dict_by_video_url\n",
    "audio_metadata_df = pd.DataFrame.from_dict(\n",
    "    audio_metadata_dict_by_video_url, orient=\"index\"\n",
    ")\n",
    "\n",
    "# Reset the index into a \"url\" column\n",
    "audio_metadata_df.reset_index(inplace=True, names=[\"url\"])\n",
    "\n",
    "# Explode the \"segments\" column\n",
    "audio_metadata_df = audio_metadata_df.explode(\"segments\")\n",
    "\n",
    "# Rename the \"segment\" column to \"segment\" in the audio_metadata_df\n",
    "audio_metadata_df = audio_metadata_df.rename(columns={\"segments\": \"segment\"})\n",
    "\n",
    "# Add a \"created_at\" column to the audio_metadata_df\n",
    "audio_metadata_df[\"created_at\"] = datetime.datetime.now()\n",
    "\n",
    "# Alter the \"text\" column so that it's extracted from the \"segment\" column\n",
    "audio_metadata_df[\"text\"] = audio_metadata_df[\"segment\"].apply(\n",
    "    lambda x: x.get(\"text\", None)\n",
    ")\n",
    "\n",
    "# Add a \"segment_type\" column to the audio_metadata_df\n",
    "audio_metadata_df[\"segment_type\"] = \"small_segment\"\n",
    "\n",
    "# We're going to extract some columns from the `segment` dictionary\n",
    "segment_columns_to_keep = [\"id\", \"seek\", \"start\", \"end\"]\n",
    "normalized_segments_df = pd.json_normalize(audio_metadata_df[\"segment\"])\n",
    "normalized_segments_df = normalized_segments_df[segment_columns_to_keep]\n",
    "\n",
    "# Rename all of the columns so that they have \"segment_\" prepended to them\n",
    "normalized_segments_df = normalized_segments_df.rename(\n",
    "    columns={col: f\"segment_{col}\" for col in normalized_segments_df.columns}\n",
    ")\n",
    "\n",
    "# Make the final_transcription_df\n",
    "final_transcription_df = pd.concat(\n",
    "    [\n",
    "        audio_metadata_df.drop(columns=[\"segment\"]).reset_index(drop=True),\n",
    "        normalized_segments_df.reset_index(drop=True),\n",
    "    ],\n",
    "    axis=1,\n",
    ").copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a little trickier than I thought. I'll also want to add \"full video\" transcriptions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate through each of the unique URLs in the final_transcription_df, and\n",
    "# create a new \"segment\" row for each of them. This row will have the \"segment_type\"\n",
    "# of \"full_segment\", and the \"segment_text\" will be the concatenation of all of the\n",
    "# \"text\" values for that video. The segment_start will be 0, and the segment_end will\n",
    "# be the length of the video.\n",
    "new_rows = []\n",
    "for video_url in final_transcription_df[\"url\"].unique():\n",
    "    # Subset the final_transcription_df to just the rows for this video_url\n",
    "    cur_video_url_df = final_transcription_df[\n",
    "        final_transcription_df[\"url\"] == video_url\n",
    "    ]\n",
    "\n",
    "    # Create a full transcription for this video\n",
    "    full_transcription = \"\".join(\n",
    "        cur_video_url_df.sort_values(\"segment_start\")[\"text\"]\n",
    "    ).strip()\n",
    "\n",
    "    # Create a new segment_id\n",
    "    segment_id = -1\n",
    "\n",
    "    # Calculate the maximum segment_seek\n",
    "    segment_seek = cur_video_url_df[\"segment_seek\"].max()\n",
    "\n",
    "    # Calculate the earliest segment_start and the latest segment_end\n",
    "    segment_start = cur_video_url_df[\"segment_start\"].min()\n",
    "    segment_end = cur_video_url_df[\"segment_end\"].max()\n",
    "\n",
    "    # Add a new row to the new_rows list\n",
    "    new_rows.append(\n",
    "        {\n",
    "            \"url\": video_url,\n",
    "            \"text\": full_transcription,\n",
    "            \"language\": \"en\",\n",
    "            \"created_at\": datetime.datetime.now(),\n",
    "            \"segment_type\": \"full_transcription\",\n",
    "            \"segment_id\": segment_id,\n",
    "            \"segment_seek\": segment_seek,\n",
    "            \"segment_start\": segment_start,\n",
    "            \"segment_end\": segment_end,\n",
    "        }\n",
    "    )\n",
    "\n",
    "# Add these new rows to the table\n",
    "final_transcription_df = pd.DataFrame.from_records(\n",
    "    final_transcription_df.to_dict(orient=\"records\") + new_rows\n",
    ")\n",
    "\n",
    "# Deduplicate on the video_id and segment_id\n",
    "final_transcription_df = final_transcription_df.drop_duplicates(\n",
    "    subset=[\"url\", \"segment_id\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, I'll make a temporary table. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'neural-needledrop.backend_data.temp_transcriptions'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the name of the table we're going to create\n",
    "table_name = \"temp_transcriptions\"\n",
    "\n",
    "# Create the table\n",
    "gbq_utils.create_temporary_table_in_gbq(\n",
    "    dataframe=final_transcription_df,\n",
    "    project_id=GBQ_PROJECT_ID,\n",
    "    dataset_name=GBQ_DATASET_ID,\n",
    "    table_name=table_name,\n",
    "    if_exists=\"replace\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, with this temporary table in hand, I'm going to try and identify the videos whose transcriptions haven't been added yet. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following query will determine which transcripts we need to upload\n",
    "transcripts_to_upload_query = f\"\"\"\n",
    "SELECT\n",
    "  DISTINCT(temp_transcript.url)\n",
    "FROM\n",
    "  `backend_data.temp_transcriptions` temp_transcript\n",
    "LEFT JOIN\n",
    "  `backend_data.transcriptions` transcript\n",
    "ON\n",
    "  transcript.url = temp_transcript.url\n",
    "WHERE\n",
    "  transcript.created_at IS NULL\n",
    "\"\"\"\n",
    "\n",
    "# Execute the query\n",
    "transcripts_to_upload_df = pd.read_gbq(\n",
    "    transcripts_to_upload_query, project_id=GBQ_PROJECT_ID\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've cross-referenced with the table, let's upload them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 2500 row(s) into backend_data:transcriptions.\n"
     ]
    }
   ],
   "source": [
    "# Create a DataFrame containing the transcripts that we need to upload\n",
    "final_transcriptions_to_upload_df = final_transcription_df.merge(\n",
    "    transcripts_to_upload_df, on=\"url\"\n",
    ")\n",
    "\n",
    "# Use the gbq_utils to add rows to the `backend_data.transcriptions` table\n",
    "gbq_utils.add_rows_to_table(\n",
    "    project_id=GBQ_PROJECT_ID,\n",
    "    dataset_id=GBQ_DATASET_ID,\n",
    "    table_id=\"transcriptions\",\n",
    "    rows=final_transcription_df.to_dict(orient=\"records\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we'll delete the `temp_transactions` table and the `temp_data` directory. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table backend_data:temp_transcriptions does not exist.\n"
     ]
    }
   ],
   "source": [
    "# Delete the temporary table\n",
    "gbq_utils.delete_table(\n",
    "    project_id=GBQ_PROJECT_ID,\n",
    "    dataset_id=GBQ_DATASET_ID,\n",
    "    table_id=table_name,\n",
    ")\n",
    "\n",
    "# Delete the temp_data directory and everything in it\n",
    "for child_file in Path(\"temp_data/\").iterdir():\n",
    "    child_file.unlink()\n",
    "Path(\"temp_data/\").rmdir()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Enriching Video Metadata\n",
    "The next part of the pipeline involves enriching the video data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embedding Transcriptions\n",
    "Next up: we're going to embed some of the different audio transcriptions we've got. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
