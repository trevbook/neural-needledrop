{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Finalizing Pipeline**\n",
    "In **`02. Prototyping Data Pipeline`**, I scoped out the entire data pipeline. Once I knew that it was running properly, I wanted to make it more configurable and contained. \n",
    "\n",
    "This notebook is going to be similar to that notebook, but will invoke entire configurable pipeline methods instead of multiple-cell stretches for each section. \n",
    "\n",
    "Each of the methods invoked will correspond with a step of the pipeline. There are a couple of different ones: \n",
    "\n",
    "- **Initialize Cloud Resources:** This will make sure that all of the GBQ tables & GCS buckets exist. It'll have an optional attribute for deleting *everything*. \n",
    "\n",
    "- **Download Video Metadata:** Next up: downloading some video metadata. This will identify which videos that a user needs to find, and then uses `pytube` to download some metadata. \n",
    "\n",
    "- **Enrich Video Metadata:** This step will determine what type of video each video is (album review, weekly track roundup, etc.), and extract review scores from the description\n",
    "\n",
    "- **Downloading Video Audio:** This step will download the audio of videos we haven't downloaded yet\n",
    "\n",
    "- **Transcribing Audio:** Next: this step uses OpenAI's Whisper model to transcribe all of the audio we've downloaded. \n",
    "\n",
    "- **Embedding Transcriptions:** Finally, we're going to embed some of the transcriptions that we've created using Whisper. \n",
    "\n",
    "Each of these methods shares a couple of key design steps: \n",
    "\n",
    "- Idempotency: The methods can be retried, and won't necessarily overwrite things\n",
    "- Logging: Each of the methods logs information (using various logging levels) to Google Cloud Logging \n",
    "- Configurable: Different parameters of the pipeline step can be indicated through command line arguments. I've also got a way to load in these configurations via .yml files. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup\n",
    "The cells below will set up the rest of the notebook.\n",
    "\n",
    "I'll start by configuring the kernel: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d:\\data\\programming\\neural-needledrop\\pipeline\n"
     ]
    }
   ],
   "source": [
    "# Change the working directory \n",
    "%cd ..\n",
    "\n",
    "# Enable the autoreload extension, which will automatically load in new code as it's written\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I'll import some necessary modules:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: LOG_TO_CONSOLE=True\n",
      "env: LOG_LEVEL=DEBUG\n",
      "env: TQDM_ENABLED=True\n"
     ]
    }
   ],
   "source": [
    "# Set up some environment variables to configure the logging \n",
    "%env LOG_TO_CONSOLE=True\n",
    "%env LOG_LEVEL=DEBUG\n",
    "%env TQDM_ENABLED=True\n",
    "\n",
    "# General import statements\n",
    "import pandas as pd\n",
    "\n",
    "# Import each of the different jobs\n",
    "from jobs.initialize_cloud_resources import run_initialize_cloud_resources_job\n",
    "from jobs.download_video_metadata import run_download_video_metadata_job\n",
    "from jobs.enrich_video_metadata import run_enrich_video_metadata_job\n",
    "from jobs.download_audio import run_download_audio_job\n",
    "from jobs.transcribe_audio import run_transcribe_audio_job\n",
    "from jobs.embed_transcriptions import run_embed_transcriptions_job"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running Jobs\n",
    "Below, I'm going to run each of the individual jobs. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize Cloud Resources\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-27 15:27:21,901 - pipeline.initialize_resources - INFO - Starting the INITIALIZE RESOURCES job.\n",
      "2024-01-27 15:27:27,775 - pipeline.initialize_resources - DEBUG - Dataset neural-needledrop.backend_data already exists.\n",
      "2024-01-27 15:27:27,777 - pipeline.initialize_resources - DEBUG - Running table generation method for video_metadata\n",
      "2024-01-27 15:27:28,133 - pipeline.initialize_resources - DEBUG - Table neural-needledrop.backend_data.video_metadata already exists.\n",
      "2024-01-27 15:27:28,135 - pipeline.initialize_resources - DEBUG - Running table generation method for audio\n",
      "2024-01-27 15:27:28,386 - pipeline.initialize_resources - DEBUG - Table neural-needledrop.backend_data.audio already exists.\n",
      "2024-01-27 15:27:28,388 - pipeline.initialize_resources - DEBUG - Running table generation method for transcriptions\n",
      "2024-01-27 15:27:28,738 - pipeline.initialize_resources - DEBUG - Table neural-needledrop.backend_data.transcriptions already exists.\n",
      "2024-01-27 15:27:28,740 - pipeline.initialize_resources - DEBUG - Running table generation method for enriched_video_metadata\n",
      "2024-01-27 15:27:29,104 - pipeline.initialize_resources - DEBUG - Table neural-needledrop.backend_data.enriched_video_metadata already exists.\n",
      "2024-01-27 15:27:29,106 - pipeline.initialize_resources - DEBUG - Running table generation method for embeddings\n",
      "2024-01-27 15:27:29,456 - pipeline.initialize_resources - DEBUG - Table neural-needledrop.backend_data.embeddings already exists.\n",
      "2024-01-27 15:27:29,458 - pipeline.initialize_resources - DEBUG - Running table generation method for age_restricted\n",
      "2024-01-27 15:27:29,812 - pipeline.initialize_resources - DEBUG - Table neural-needledrop.backend_data.age_restricted already exists.\n",
      "2024-01-27 15:27:30,517 - pipeline.initialize_resources - DEBUG - Bucket neural-needledrop.neural-needledrop-audio already exists\n",
      "2024-01-27 15:27:30,642 - pipeline.initialize_resources - DEBUG - Bucket neural-needledrop.neural-needledrop-embeddings already exists\n",
      "2024-01-27 15:27:30,643 - pipeline.initialize_resources - INFO - Finished the INITIALIZE RESOURCES job.\n"
     ]
    }
   ],
   "source": [
    "# Run the initialize resources job\n",
    "run_initialize_cloud_resources_job()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downloading Video Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-27 15:34:36,054 - pipeline.download_video_metadata - INFO - Determining whether or not to scrape this channel.\n",
      "d:\\data\\programming\\neural-needledrop\\pipeline\\jobs\\download_video_metadata.py:67: FutureWarning: read_gbq is deprecated and will be removed in a future version. Please use pandas_gbq.read_gbq instead: https://pandas-gbq.readthedocs.io/en/latest/api.html#pandas_gbq.read_gbq\n",
      "  most_recent_date = (\n",
      "2024-01-27 15:34:38,133 - pipeline.download_video_metadata - INFO - Skipping scraping for channel https://www.youtube.com/c/theneedledrop because we've already scraped it within the last 7 days.\n"
     ]
    }
   ],
   "source": [
    "# Run the download video metadata job\n",
    "run_download_video_metadata_job(\n",
    "    channel_url=\"https://www.youtube.com/c/theneedledrop\",\n",
    "    video_limit=10,\n",
    "    stop_at_most_recent_video=True,\n",
    "    video_parse_step_size=25,\n",
    "    time_to_sleep_between_requests=2,\n",
    "    sleep_time_multiplier=2.25,\n",
    "    n_days_to_not_scrape=7,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enrich Video Metadata\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the enrich video metadata job\n",
    "run_enrich_video_metadata_job()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downloading Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the run_download_audio_job\n",
    "run_download_audio_job(\n",
    "    n_max_videos_to_download=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transcribing Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the transcribe_audio job\n",
    "run_transcribe_audio_job(\n",
    "    n_max_to_transcribe=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedding Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the embed_transcriptions job\n",
    "run_embed_transcriptions_job(max_videos_to_embed=700)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
